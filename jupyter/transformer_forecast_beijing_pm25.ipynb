{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1159,"status":"ok","timestamp":1644014208643,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"hqTzrIYbiSfZ"},"outputs":[],"source":["import os\n","import sys\n","import pathlib\n","import getpass"]},{"cell_type":"markdown","metadata":{"id":"opxQhQ8bzipb"},"source":["## Environment Setup\n","\n","This section checks the runtime environment to see if the notebook is running inside a Google Colab instance. If it is, then it installs the `makassar-ml` package from the GitHub repo and mounts the user's Google Drive folder to the workspace."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644014209277,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"KfK265ryiSfc","outputId":"dd897cb2-a872-4769-85cd-740cc56bee71"},"outputs":[{"name":"stdout","output_type":"stream","text":["NOT IN COLAB\n"]}],"source":["# Detect if running in Google Colab environment.\n","# If so, then clone/install package from GitHub.\n","# Otherwise, use locally.\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print('IN COLAB')\n","\n","except:\n","    IN_COLAB = False\n","    print('NOT IN COLAB')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15271,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"8fT3V4PxzUUM","outputId":"54fd69f1-590f-42f3-ddd8-fc5a5777b0c9"},"outputs":[],"source":["# Install package from GitHub if in Google Drive.\n","if IN_COLAB:\n","    config_path = pathlib.Path('./config.json')\n","    if config_path.exists():\n","        import json\n","        with open(config_path, 'r') as f:\n","            j = json.load(f)\n","        os.environ['GITHUB_TOKEN'] = j['GITHUB_TOKEN']\n","\n","    else:\n","\n","        # Request GitHub access token.\n","        if os.getenv('GITHUB_TOKEN',None) is None:\n","            os.environ['GITHUB_TOKEN'] = getpass.getpass('GitHub Token: ')\n","        else:\n","            print('Using cached GitHub Token')\n","        \n","        import json\n","        with open(config_path, 'w+') as f:\n","            json.dump(\n","                {'GITHUB_TOKEN': os.environ['GITHUB_TOKEN']}, \n","                f,\n","            )\n","\n","    # Clone or update repo.\n","    repo = \"makassar-ml\"\n","    repo_url = f\"https://{os.environ['GITHUB_TOKEN']}@github.com/news-vt/{repo}.git\"\n","    repo_path = f\"/content/{repo}\"\n","    repo_branch = \"develop\"\n","    ![ -d $repo_path ] && git -C $repo_path pull || git clone --branch $repo_branch $repo_url\n","    # !git clone --branch $repo_branch $repo_url\n","\n","    # Install repo to ensure dependencies are resolved.\n","    !pip install --upgrade $repo_path\n","\n","    # Add package location to path.\n","    sys.path.insert(0, repo_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Cc2L8BmWiSfc"},"outputs":[],"source":["# Install future annotations for <3.7\n","if sys.version_info < (3,7):\n","    !pip install future-annotations"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3398,"status":"ok","timestamp":1644014227938,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"AjSOQCT5xf5P","outputId":"bb1521a5-fc1b-4d02-d224-61be9fc95ea3"},"outputs":[],"source":["# Model save location in Google Drive.\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014227939,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"X-21x9NBxkIV"},"outputs":[],"source":["# Set dataset and model checkpoint root directories.\n","if IN_COLAB:\n","    dataset_root = pathlib.Path(f'/content/gdrive/My Drive/ml/datasets')\n","    checkpoint_root = pathlib.Path(f'/content/gdrive/My Drive/ml/makassar-ml/checkpoints')\n","else:\n","    dataset_root = pathlib.Path('../datasets/')\n","    checkpoint_root = pathlib.Path('../model_checkpoints/')"]},{"cell_type":"markdown","metadata":{"id":"5tN6e7iGzyRO"},"source":["## Model Definitions"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1846,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"GBX0zomgiSfd"},"outputs":[],"source":["from __future__ import annotations\n","import makassar_ml as ml\n","import pytorch_lightning as pl\n","import torch\n","from typing import Optional"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"02ushc2diSfd"},"outputs":[],"source":["class BeijingPM25LightningDataModule(pl.LightningDataModule):\n","    def __init__(self, \n","        root: str, \n","        feature_cols: list[int], \n","        target_cols: list[int], \n","        history: int, \n","        horizon: int, \n","        split: float,\n","        batch_size: int,\n","        ):\n","        self.root = root\n","        self.feature_cols = feature_cols\n","        self.target_cols = target_cols\n","        self.history = history\n","        self.horizon = horizon\n","        self.split = split\n","        self.batch_size = batch_size\n","\n","    def prepare_data(self):\n","        # Download the dataset.\n","        ml.datasets.BeijingPM25Dataset(\n","            root=self.root,\n","            download=True,\n","            )\n","\n","    def setup(self, stage: Optional[str] = None):\n","\n","        # Create train/val datasets for dataloaders.\n","        if stage == 'fit' or stage is None:\n","            dataset_train_full = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=True,\n","                split=self.split,\n","                )\n","            train_n = len(dataset_train_full)\n","            train_val_cutoff = train_n - round(train_n*.25) # 75% train, 25% val\n","\n","            self.dataset_train = torch.utils.data.Subset(dataset_train_full, list(range(0, train_val_cutoff)))\n","            self.dataset_val = torch.utils.data.Subset(dataset_train_full, list(range(train_val_cutoff, train_n)))\n","\n","            self.dataset_train_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_train,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","            self.dataset_val_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_val,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","        # Create test dataset for dataloaders.\n","        if stage == 'test' or stage is None:\n","            self.dataset_test = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=False,\n","                split=self.split,\n","                )\n","            self.dataset_test_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_test,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_train_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_val_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_test_wrap,\n","            batch_size=self.batch_size,\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"mwwvwFLxiSfe"},"outputs":[],"source":["# Note that for Transformer decoder target mask,\n","# the `length` parameter is the desired length of\n","# the target sequence.\n","# See docs: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward\n","def create_attn_mask(length: int):\n","    \"\"\"Generate mask used for attention mechanisms.\n","\n","    Masks are a lower-triangular matrix of zeros\n","    with the other entries taking value \"-inf\".\n","\n","    Args:\n","        length (int): Length of square-matrix dimension.\n","\n","    Examples:\n","        >>> create_attn_mask(3)\n","        tensor([[0., -inf, -inf],\n","                [0., 0., -inf],\n","                [0., 0., 0.]])\n","    \"\"\"\n","    # Get lower-triangular matrix of ones.\n","    mask = torch.tril(torch.ones(length, length))\n","\n","    # Replace 0 -> \"-inf\" and 1 -> 0.0\n","    mask = (\n","        mask\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"kTNd39bmiSfe"},"outputs":[],"source":["class TimeseriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_input_features: int,\n","        n_output_features: int,\n","        d_time_embed: int,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        n_encoder_layers: int = 4,\n","        n_decoder_layers: int = 4,\n","        n_encoder_heads: int = 8,\n","        n_decoder_heads: int = 8,\n","        ):\n","        super().__init__()\n","\n","        self.batch_first = batch_first\n","\n","        # Time embedding.\n","        self.time_projection = ml.time2vec.Time2Vec(input_dim=n_input_features, embed_dim=d_time_embed)\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=d_time_embed, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_output_features, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=n_encoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=n_decoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=n_encoder_layers)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=n_decoder_layers)\n","\n","        # Linear output layer.\n","        # We typically only predict a single data point at a time, so output features is typically 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=n_output_features)\n","\n","    def encode(self, src: torch.Tensor) -> torch.Tensor:\n","\n","        # Embed the source into time-feature dimensions.\n","        x = self.time_projection(src)\n","\n","        # Transform time embedding into arbitrary feature space\n","        # for the attention encoder model.\n","        x = self.encoder_projection(x)\n","\n","        # # Create source mask.\n","        # if self.batch_first:\n","        #     src_length = src.size(1)\n","        # else:\n","        #     src_length = src.size(0)\n","        # src_mask = create_attn_mask(length=src_length).to(device=self.device)\n","\n","        # Pass the linear transformation through the encoder layers.\n","        # x = self.encoder(x, mask=src_mask)\n","        x = self.encoder(x)\n","\n","        return x\n","\n","    def decode(self,\n","        tgt: torch.Tensor,\n","        memory: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        \"\"\"Decode function.\n","\n","        Args:\n","            tgt (torch.Tensor): The sequence to the decoder\n","            memory (torch.Tensor): The sequence from the last layer of the encoder\n","\n","        Returns:\n","            torch.Tensor: Decoded sequence.\n","        \"\"\"\n","        # Transform target into arbitrary feature space.\n","        x = self.decoder_projection(tgt)\n","\n","        # Pass the linear transformation through the decoder layers.\n","        x = self.decoder(tgt=x, memory=memory, tgt_mask=tgt_mask)\n","\n","        # Pass the output of the decoder through the linear prediction layer.\n","        x = self.linear(x)\n","        return x\n","\n","    def forward(self, \n","        src: torch.Tensor,\n","        tgt: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        x = self.encode(src)\n","        y = self.decode(tgt=tgt, memory=x, tgt_mask=tgt_mask)\n","        return y"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1644014230275,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"DY6IgfFtiSff"},"outputs":[],"source":["class BeijingPM25ForecastTransformer(pl.LightningModule):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__()\n","        self.criterion = torch.nn.MSELoss(reduction='mean')\n","\n","        # Create the transformer model.\n","        self.model = TimeseriesTransformer(*args, **kwargs)\n","\n","        # Copy batch-first member if the underlying model has one.\n","        self.batch_first = getattr(self.model, 'batch_first', False)\n","\n","        # Save parameters for checkpoint.\n","        self.save_hyperparameters()\n","\n","    def forward(self, *args, **kwargs) -> torch.Tensor:\n","        return self.model(*args, **kwargs)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(\n","            self.model.parameters(), \n","            lr=1e-3, \n","            betas=[0.9, 0.98], \n","            eps=1e-9,\n","            )\n","\n","    def compute_loss(self, y_hat, y):\n","        return self.criterion(y_hat, y)\n","\n","    def step(self, batch: torch.Tensor, batch_idx: int, stage: str) -> float:\n","        \"\"\"Generic step function used for train/validation/test loops.\n","\n","        Args:\n","            batch (torch.Tensor): Tensor of batched records.\n","            batch_idx (int): Index of batch relative to entire dataset.\n","            stage (str): Stage key for logging purposes (one of ['train','val','test']).\n","\n","        Returns:\n","            float: Prediction loss.\n","        \"\"\"\n","        history_x, history_y, horizon_x, horizon_y = batch\n","\n","        # Create decoder input sequence.\n","        # This should start with the last element of the encoder sequence\n","        # and end with the second-to-last element of the target sequence.\n","        if self.model.batch_first:\n","            tgt = torch.cat(\n","                (history_x[:,[-1],:], horizon_x[:,:-1,:]),\n","                dim=1,\n","                )\n","        else:\n","            tgt = torch.cat(\n","                (history_x[[-1],:,:], horizon_x[:-1,:,:]),\n","                dim=0,\n","                )\n","        \n","        # Create target attention mask to prevent lookahead cheating.\n","        if self.model.batch_first:\n","            tgt_length = tgt.size(1)\n","        else:\n","            tgt_length = tgt.size(0)\n","        tgt_mask = create_attn_mask(length=tgt_length).to(device=self.device)\n","\n","        # Pass source and target sequences into the transformer.\n","        y_hat = self(history_x, tgt, tgt_mask)\n","\n","        # Compute loss.\n","        # loss = self.compute_loss(y_hat, horizon_y)\n","        loss = self.compute_loss(y_hat, horizon_x)\n","        self.log(f'{stage}_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def training_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='train')\n","\n","    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='val')\n","\n","    def test_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='test')"]},{"cell_type":"markdown","metadata":{"id":"t49alRI1z2NC"},"source":["## Training"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014230276,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"qmJYNNj7sN4j"},"outputs":[],"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir ./lightning_logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["7b156f6baa5146f48bedc3b7b77040f6","cc28ff68de5a438098244f4c06261d55","248600bc5895449daf1881c31dbc59f7","9e3c7c77fa644e0f9c96bcac2c9b3afb","f5de1191a0e148ec980ab2a7ca59aadc","aa7879ce50474acaaa5268ae6ce8adbd","7c9fa4ed7c72494f8772bf9fbea846c4","974dd36ec5da4d668837dafb500252f4","109008f349da49b9905d241ad688ac5f","44c207d84dcd42baba74145845a0eaae","cf25700894134e859f3b861825cfbd5b","828595d897f44fe69e29c2b5b7f5d03a","e2ec3d6a189a46e4a3ff8b44b4ffbd7f","d6769dc07c644db3bfd09e23414ae3c2","2875c07472a14c90a3cff89f74627f94","ba96567da16c4100a61bd4d8d0194305","9c54a70e757d428c855909b63d38c605","f2b1ef77bfdb43948ccb1d5b7d5a79b7","3aacf9733f6a462bbd93b726f174a7b4","2c448eb03c3340dfbed25ad427467a91","97f6207712314a23a0d567981c2ac984","9f575a54b0fb4c7f9f4fec8a77e06abf","a587b85218fa427997ac35550f4f2a64","55306708010f4674b24af0e61aeca429","810f8cba8fba4d9bbb730f4791a9f266","e7f69c1faea447ccb7bc3e525e32da93","3352ff05e88a4a09bc2f5e082cda1755","9f70ed05ee694ab199fe4f783439cc88","2e307bcd8dda445d8eb04fc21af6cc7b","e45df65595364c1c8c58d16f743ca421","47dfccf1b5024a7b869650d1456978f4","8f4e666ac3764f45a3f2f453626fbdd8","6b59d72baac847cb8bd03c0888489b2a"]},"executionInfo":{"elapsed":157485,"status":"ok","timestamp":1644014387757,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"2y1QHCUuiSfg","outputId":"a868883b-e8bf-4860-9d79-1ebd0794a5bc"},"outputs":[],"source":["# Define parameters for the dataset.\n","# feature_cols = [0,1,2,3]\n","feature_cols = [6]\n","target_cols = [-3]\n","history = 5\n","horizon = 3\n","# split = 0.15\n","split = 0.75\n","batch_size = 64\n","\n","# Create the dataset.\n","dm = BeijingPM25LightningDataModule(\n","    root=dataset_root,\n","    feature_cols=feature_cols,\n","    target_cols=target_cols,\n","    history=history,\n","    horizon=horizon,\n","    split=split,\n","    batch_size=batch_size,\n",")\n","\n","n_input_features: int = len(feature_cols)\n","# n_output_features: int = len(target_cols)\n","n_output_features: int = len(feature_cols)\n","d_time_embed = 6 * n_input_features # Time embedding dimension should be a multiple of the input feature dimension.\n","d_model: int = 512\n","dropout: float = 0.2\n","n_encoder_layers: int = 4\n","n_decoder_layers: int = 4\n","model = BeijingPM25ForecastTransformer(\n","    n_input_features=n_input_features,\n","    n_output_features=n_output_features,\n","    d_time_embed=d_time_embed,\n","    d_model=d_model,\n","    dropout=dropout,\n","    batch_first=True,\n","    n_encoder_layers=n_encoder_layers,\n","    n_decoder_layers=n_decoder_layers,\n","    )"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n"]}],"source":["TRAIN = True\n","\n","kwargs = {}\n","\n","# Devlopment mode.\n","kwargs['fast_dev_run'] = True\n","kwargs['detect_anomaly'] = True\n","\n","if torch.cuda.is_available():\n","    kwargs['gpus'] = 1\n","\n","if TRAIN:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        monitor=\"val_loss\",\n","        mode='min',\n","        dirpath=checkpoint_root,\n","        filename='beijing-pm25-transformer-{epoch:02d}-{train_loss:.2f}-{val_loss:.2f}',\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","else:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        dirpath=checkpoint_root,\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","\n","trainer = pl.Trainer(**kwargs)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","  | Name      | Type                  | Params\n","----------------------------------------------------\n","0 | criterion | MSELoss               | 0     \n","1 | model     | TimeseriesTransformer | 29.4 M\n","----------------------------------------------------\n","29.4 M    Trainable params\n","0         Non-trainable params\n","29.4 M    Total params\n","117.723   Total estimated model params size (MB)\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  rank_zero_warn(\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 2/2 [00:09<00:00,  4.70s/it, loss=49.5, v_num=, train_loss_step=49.50, val_loss_step=85.90, val_loss_epoch=85.90, train_loss_epoch=49.50]\n"]}],"source":["# Train or load the model.\n","trainer.fit(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"dkCNxcZsjXI9"},"source":["## Testing\n","\n","Here we try to forecast some features and plot them to see how well model does."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Hs3ZpYr1jXI-"},"outputs":[],"source":["# trainer.test(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"_YuL2rAuz5E3"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"OoGeObrywRrl"},"outputs":[],"source":["def evaluate(model: torch.nn.Module, data: torch.Tensor, horizon: int) -> torch.Tensor:\n","\n","    # Prepare output sequence tensor.\n","    if model.batch_first:\n","        dim_batch, dim_seq, dim_feat = data.shape\n","    else:\n","        dim_seq, dim_batch, dim_feat = data.shape\n","    out_seq = torch.empty((dim_batch, 0, dim_feat))\n","\n","    model.eval()\n","    with torch.no_grad():\n","        while True:\n","            # Create decoder input sequence.\n","            # This should start with the last element of the encoder sequence\n","            # and end with the second-to-last element of the target sequence.\n","            if model.batch_first: # Batch dimension first.\n","                tgt = data[:,[-1],:]\n","            else: # Sequence dimension first.\n","                tgt = data[[-1],:,:]\n","\n","            # Pass source and target sequences into the transformer.\n","            y_hat = model(data, tgt)\n","            # print(y_hat.shape)\n","            print('out_seq.shape',out_seq.shape)\n","\n","            # Add predicted value to output sequence.\n","            # out_seq.append(y_hat)\n","            if model.batch_first:\n","                out_seq = torch.cat(\n","                    (out_seq, y_hat),\n","                    dim=1,\n","                )\n","            else:\n","                out_seq = torch.cat(\n","                    (out_seq, y_hat),\n","                    dim=0,\n","                )\n","\n","            # Shift the input and target.\n","            if model.batch_first: # Batch dimension first.\n","                data = torch.cat(\n","                    (data[:,1:,:], y_hat),\n","                    dim=1,\n","                    )\n","            else:\n","                data = torch.cat(\n","                    (data[1:,:,:], y_hat),\n","                    dim=0,\n","                    )\n","\n","            # Check if sequence length has been reached.\n","            seq_len = out_seq.size(1 if model.batch_first else 0)\n","            if seq_len >= horizon:\n","                break\n","\n","    return out_seq"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["out_seq.shape torch.Size([1, 0, 1])\n","out_seq.shape torch.Size([1, 1, 1])\n","out_seq.shape torch.Size([1, 2, 1])\n"]}],"source":["dm.setup('test')\n","history_x, history_y, horizon_x, horizon_y = dm.dataset_test_wrap[0] # Get first test window.\n","history_x = history_x.unsqueeze(0) # Add batch dimension.\n","history_y = history_y.unsqueeze(0)\n","horizon_x = horizon_x.unsqueeze(0)\n","horizon_y = horizon_y.unsqueeze(0)\n","\n","out_seq = evaluate(\n","    model,\n","    history_x,\n","    horizon,\n","    )"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x12a48ae80>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Plot the evaluation predictions\n","import matplotlib.pyplot as plt\n","\n","for idx,batch in enumerate(out_seq):\n","    plt.plot(torch.arange(0, history_x.size(1)), history_x[idx], label=f\"X batch {idx}\")\n","    plt.plot(torch.arange(history_x.size(1),history_x.size(1)+batch.size(0)), batch, label=f\"Y batch {idx}\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"transformer_forecast_beijing_pm25.ipynb","provenance":[]},"interpreter":{"hash":"73cda5dbe0541404945d78922515ddeb5c5d95f647b0e783aaf5c1a9a2d741fd"},"kernelspec":{"display_name":"Python 3.9.2 64-bit ('3.9.2': pyenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"109008f349da49b9905d241ad688ac5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"248600bc5895449daf1881c31dbc59f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9fa4ed7c72494f8772bf9fbea846c4","placeholder":"​","style":"IPY_MODEL_aa7879ce50474acaaa5268ae6ce8adbd","value":"Validation sanity check: 100%"}},"2875c07472a14c90a3cff89f74627f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c448eb03c3340dfbed25ad427467a91","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aacf9733f6a462bbd93b726f174a7b4","value":100}},"2c448eb03c3340dfbed25ad427467a91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e307bcd8dda445d8eb04fc21af6cc7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3352ff05e88a4a09bc2f5e082cda1755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b59d72baac847cb8bd03c0888489b2a","placeholder":"​","style":"IPY_MODEL_8f4e666ac3764f45a3f2f453626fbdd8","value":" 43/43 [00:15&lt;00:00,  2.82it/s]"}},"3aacf9733f6a462bbd93b726f174a7b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44c207d84dcd42baba74145845a0eaae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47dfccf1b5024a7b869650d1456978f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55306708010f4674b24af0e61aeca429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6b59d72baac847cb8bd03c0888489b2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b156f6baa5146f48bedc3b7b77040f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_248600bc5895449daf1881c31dbc59f7","IPY_MODEL_9e3c7c77fa644e0f9c96bcac2c9b3afb","IPY_MODEL_f5de1191a0e148ec980ab2a7ca59aadc"],"layout":"IPY_MODEL_cc28ff68de5a438098244f4c06261d55"}},"7c9fa4ed7c72494f8772bf9fbea846c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"810f8cba8fba4d9bbb730f4791a9f266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e307bcd8dda445d8eb04fc21af6cc7b","placeholder":"​","style":"IPY_MODEL_9f70ed05ee694ab199fe4f783439cc88","value":"Validating: 100%"}},"828595d897f44fe69e29c2b5b7f5d03a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6769dc07c644db3bfd09e23414ae3c2","IPY_MODEL_2875c07472a14c90a3cff89f74627f94","IPY_MODEL_ba96567da16c4100a61bd4d8d0194305"],"layout":"IPY_MODEL_e2ec3d6a189a46e4a3ff8b44b4ffbd7f"}},"8f4e666ac3764f45a3f2f453626fbdd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"974dd36ec5da4d668837dafb500252f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97f6207712314a23a0d567981c2ac984":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c54a70e757d428c855909b63d38c605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e3c7c77fa644e0f9c96bcac2c9b3afb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_109008f349da49b9905d241ad688ac5f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_974dd36ec5da4d668837dafb500252f4","value":2}},"9f575a54b0fb4c7f9f4fec8a77e06abf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f70ed05ee694ab199fe4f783439cc88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a587b85218fa427997ac35550f4f2a64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810f8cba8fba4d9bbb730f4791a9f266","IPY_MODEL_e7f69c1faea447ccb7bc3e525e32da93","IPY_MODEL_3352ff05e88a4a09bc2f5e082cda1755"],"layout":"IPY_MODEL_55306708010f4674b24af0e61aeca429"}},"aa7879ce50474acaaa5268ae6ce8adbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba96567da16c4100a61bd4d8d0194305":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f575a54b0fb4c7f9f4fec8a77e06abf","placeholder":"​","style":"IPY_MODEL_97f6207712314a23a0d567981c2ac984","value":" 100/172 [01:03&lt;00:46,  1.56it/s, loss=29.8, v_num=4, train_loss_step=74.20, val_loss_step=163.0, val_loss_epoch=49.50, train_loss_epoch=33.80]"}},"cc28ff68de5a438098244f4c06261d55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cf25700894134e859f3b861825cfbd5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6769dc07c644db3bfd09e23414ae3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b1ef77bfdb43948ccb1d5b7d5a79b7","placeholder":"​","style":"IPY_MODEL_9c54a70e757d428c855909b63d38c605","value":"Epoch 1:  58%"}},"e2ec3d6a189a46e4a3ff8b44b4ffbd7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e45df65595364c1c8c58d16f743ca421":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7f69c1faea447ccb7bc3e525e32da93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_47dfccf1b5024a7b869650d1456978f4","max":43,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e45df65595364c1c8c58d16f743ca421","value":43}},"f2b1ef77bfdb43948ccb1d5b7d5a79b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5de1191a0e148ec980ab2a7ca59aadc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf25700894134e859f3b861825cfbd5b","placeholder":"​","style":"IPY_MODEL_44c207d84dcd42baba74145845a0eaae","value":" 2/2 [00:01&lt;00:00,  1.09it/s]"}}}}},"nbformat":4,"nbformat_minor":0}
