{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1159,"status":"ok","timestamp":1644014208643,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"hqTzrIYbiSfZ"},"outputs":[],"source":["import os\n","import sys\n","import pathlib\n","import getpass"]},{"cell_type":"markdown","metadata":{"id":"opxQhQ8bzipb"},"source":["## Environment Setup\n","\n","This section checks the runtime environment to see if the notebook is running inside a Google Colab instance. If it is, then it installs the `makassar-ml` package from the GitHub repo and mounts the user's Google Drive folder to the workspace."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644014209277,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"KfK265ryiSfc","outputId":"dd897cb2-a872-4769-85cd-740cc56bee71"},"outputs":[{"name":"stdout","output_type":"stream","text":["NOT IN COLAB\n"]}],"source":["# Detect if running in Google Colab environment.\n","# If so, then clone/install package from GitHub.\n","# Otherwise, use locally.\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print('IN COLAB')\n","\n","except:\n","    IN_COLAB = False\n","    print('NOT IN COLAB')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15271,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"8fT3V4PxzUUM","outputId":"54fd69f1-590f-42f3-ddd8-fc5a5777b0c9"},"outputs":[],"source":["# Install package from GitHub if in Google Drive.\n","if IN_COLAB:\n","    config_path = pathlib.Path('./config.json')\n","    if config_path.exists():\n","        import json\n","        with open(config_path, 'r') as f:\n","            j = json.load(f)\n","        os.environ['GITHUB_TOKEN'] = j['GITHUB_TOKEN']\n","\n","    else:\n","\n","        # Request GitHub access token.\n","        if os.getenv('GITHUB_TOKEN',None) is None:\n","            os.environ['GITHUB_TOKEN'] = getpass.getpass('GitHub Token: ')\n","        else:\n","            print('Using cached GitHub Token')\n","        \n","        import json\n","        with open(config_path, 'w+') as f:\n","            json.dump(\n","                {'GITHUB_TOKEN': os.environ['GITHUB_TOKEN']}, \n","                f,\n","            )\n","\n","    # Clone or update repo.\n","    repo = \"makassar-ml\"\n","    repo_url = f\"https://{os.environ['GITHUB_TOKEN']}@github.com/news-vt/{repo}.git\"\n","    repo_path = f\"/content/{repo}\"\n","    repo_branch = \"develop\"\n","    ![ -d $repo_path ] && git -C $repo_path pull || git clone --branch $repo_branch $repo_url\n","    # !git clone --branch $repo_branch $repo_url\n","\n","    # Install repo to ensure dependencies are resolved.\n","    !pip install --upgrade $repo_path\n","\n","    # Add package location to path.\n","    sys.path.insert(0, repo_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Cc2L8BmWiSfc"},"outputs":[],"source":["# Install future annotations for <3.7\n","if sys.version_info < (3,7):\n","    !pip install future-annotations"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3398,"status":"ok","timestamp":1644014227938,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"AjSOQCT5xf5P","outputId":"bb1521a5-fc1b-4d02-d224-61be9fc95ea3"},"outputs":[],"source":["# Model save location in Google Drive.\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014227939,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"X-21x9NBxkIV"},"outputs":[],"source":["# Set dataset and model checkpoint root directories.\n","if IN_COLAB:\n","    dataset_root = pathlib.Path(f'/content/gdrive/My Drive/ml/datasets')\n","    checkpoint_root = pathlib.Path(f'/content/gdrive/My Drive/ml/makassar-ml/checkpoints')\n","else:\n","    dataset_root = pathlib.Path('../datasets/')\n","    checkpoint_root = pathlib.Path('../model_checkpoints/')"]},{"cell_type":"markdown","metadata":{"id":"5tN6e7iGzyRO"},"source":["## Model Definitions"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1846,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"GBX0zomgiSfd"},"outputs":[],"source":["from __future__ import annotations\n","import makassar_ml as ml\n","import pytorch_lightning as pl\n","import torch\n","from typing import Optional"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"02ushc2diSfd"},"outputs":[],"source":["class BeijingPM25LightningDataModule(pl.LightningDataModule):\n","    def __init__(self, \n","        root: str, \n","        feature_cols: list[int], \n","        target_cols: list[int], \n","        history: int, \n","        horizon: int, \n","        split: float,\n","        batch_size: int,\n","        ):\n","        self.root = root\n","        self.feature_cols = feature_cols\n","        self.target_cols = target_cols\n","        self.history = history\n","        self.horizon = horizon\n","        self.split = split\n","        self.batch_size = batch_size\n","\n","    def prepare_data(self):\n","        # Download the dataset.\n","        ml.datasets.BeijingPM25Dataset(\n","            root=self.root,\n","            download=True,\n","            )\n","\n","    def setup(self, stage: Optional[str] = None):\n","\n","        # Create train/val datasets for dataloaders.\n","        if stage == 'fit' or stage is None:\n","            dataset_train_full = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=True,\n","                split=self.split,\n","                )\n","            train_n = len(dataset_train_full)\n","            train_val_cutoff = train_n - round(train_n*.25) # 75% train, 25% val\n","\n","            self.dataset_train = torch.utils.data.Subset(dataset_train_full, list(range(0, train_val_cutoff)))\n","            self.dataset_val = torch.utils.data.Subset(dataset_train_full, list(range(train_val_cutoff, train_n)))\n","\n","            self.dataset_train_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_train,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","            self.dataset_val_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_val,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","        # Create test dataset for dataloaders.\n","        if stage == 'test' or stage is None:\n","            self.dataset_test = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=False,\n","                split=self.split,\n","                )\n","            self.dataset_test_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_test,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_train_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_val_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_test_wrap,\n","            batch_size=self.batch_size,\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"mwwvwFLxiSfe"},"outputs":[],"source":["# Note that for Transformer decoder target mask,\n","# the `length` parameter is the desired length of\n","# the target sequence.\n","# See docs: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward\n","def create_attn_mask(length: int):\n","    \"\"\"Generate mask used for attention mechanisms.\n","\n","    Masks are a lower-triangular matrix of zeros\n","    with the other entries taking value \"-inf\".\n","\n","    Args:\n","        length (int): Length of square-matrix dimension.\n","\n","    Examples:\n","        >>> create_attn_mask(3)\n","        tensor([[0., -inf, -inf],\n","                [0., 0., -inf],\n","                [0., 0., 0.]])\n","    \"\"\"\n","    # Get lower-triangular matrix of ones.\n","    mask = torch.tril(torch.ones(length, length))\n","\n","    # Replace 0 -> \"-inf\" and 1 -> 0.0\n","    mask = (\n","        mask\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"kTNd39bmiSfe"},"outputs":[],"source":["class TimeseriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_input_features: int,\n","        n_output_features: int,\n","        d_time_embed: int,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        n_encoder_layers: int = 4,\n","        n_decoder_layers: int = 4,\n","        n_encoder_heads: int = 8,\n","        n_decoder_heads: int = 8,\n","        ):\n","        super().__init__()\n","\n","        self.batch_first = batch_first\n","\n","        # Time embedding.\n","        self.time_projection = ml.time2vec.Time2Vec(input_dim=n_input_features, embed_dim=d_time_embed)\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=d_time_embed, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_output_features, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=n_encoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=n_decoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=n_encoder_layers)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=n_decoder_layers)\n","\n","        # Linear output layer.\n","        # We typically only predict a single data point at a time, so output features is typically 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=n_output_features)\n","\n","    def encode(self, src: torch.Tensor) -> torch.Tensor:\n","\n","        # Embed the source into time-feature dimensions.\n","        x = self.time_projection(src)\n","\n","        # Transform time embedding into arbitrary feature space\n","        # for the attention encoder model.\n","        x = self.encoder_projection(x)\n","\n","        # # Create source mask.\n","        # if self.batch_first:\n","        #     src_length = src.size(1)\n","        # else:\n","        #     src_length = src.size(0)\n","        # src_mask = create_attn_mask(length=src_length).to(device=self.device)\n","\n","        # Pass the linear transformation through the encoder layers.\n","        # x = self.encoder(x, mask=src_mask)\n","        x = self.encoder(x)\n","\n","        return x\n","\n","    def decode(self,\n","        tgt: torch.Tensor,\n","        memory: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        \"\"\"Decode function.\n","\n","        Args:\n","            tgt (torch.Tensor): The sequence to the decoder\n","            memory (torch.Tensor): The sequence from the last layer of the encoder\n","\n","        Returns:\n","            torch.Tensor: Decoded sequence.\n","        \"\"\"\n","        # Transform target into arbitrary feature space.\n","        x = self.decoder_projection(tgt)\n","\n","        # Pass the linear transformation through the decoder layers.\n","        x = self.decoder(tgt=x, memory=memory, tgt_mask=tgt_mask)\n","\n","        # Pass the output of the decoder through the linear prediction layer.\n","        x = self.linear(x)\n","        return x\n","\n","    def forward(self, \n","        src: torch.Tensor,\n","        tgt: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        x = self.encode(src)\n","        y = self.decode(tgt=tgt, memory=x, tgt_mask=tgt_mask)\n","        return y"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1644014230275,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"DY6IgfFtiSff"},"outputs":[],"source":["class BeijingPM25ForecastTransformer(pl.LightningModule):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__()\n","        self.criterion = torch.nn.MSELoss(reduction='mean')\n","\n","        # Create the transformer model.\n","        self.model = TimeseriesTransformer(*args, **kwargs)\n","\n","        # Copy batch-first member if the underlying model has one.\n","        self.batch_first = getattr(self.model, 'batch_first', False)\n","\n","        # Save parameters for checkpoint.\n","        self.save_hyperparameters()\n","\n","    def forward(self, *args, **kwargs) -> torch.Tensor:\n","        return self.model(*args, **kwargs)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(\n","            self.model.parameters(), \n","            lr=1e-3, \n","            betas=[0.9, 0.98], \n","            eps=1e-9,\n","            )\n","\n","    def compute_loss(self, y_hat, y):\n","        return self.criterion(y_hat, y)\n","\n","    def step(self, batch: torch.Tensor, batch_idx: int, stage: str) -> float:\n","        \"\"\"Generic step function used for train/validation/test loops.\n","\n","        Args:\n","            batch (torch.Tensor): Tensor of batched records.\n","            batch_idx (int): Index of batch relative to entire dataset.\n","            stage (str): Stage key for logging purposes (one of ['train','val','test']).\n","\n","        Returns:\n","            float: Prediction loss.\n","        \"\"\"\n","        history_x, history_y, horizon_x, horizon_y = batch\n","\n","        # Create decoder input sequence.\n","        # This should start with the last element of the encoder sequence\n","        # and end with the second-to-last element of the target sequence.\n","        if self.model.batch_first:\n","            tgt = torch.cat(\n","                (history_x[:,[-1],:], horizon_x[:,:-1,:]),\n","                dim=1,\n","                )\n","        else:\n","            tgt = torch.cat(\n","                (history_x[[-1],:,:], horizon_x[:-1,:,:]),\n","                dim=0,\n","                )\n","        \n","        # Create target attention mask to prevent lookahead cheating.\n","        if self.model.batch_first:\n","            tgt_length = tgt.size(1)\n","        else:\n","            tgt_length = tgt.size(0)\n","        tgt_mask = create_attn_mask(length=tgt_length).to(device=self.device)\n","\n","        # Pass source and target sequences into the transformer.\n","        y_hat = self(history_x, tgt, tgt_mask)\n","\n","        # Compute loss.\n","        # loss = self.compute_loss(y_hat, horizon_y)\n","        loss = self.compute_loss(y_hat, horizon_x)\n","        self.log(f'{stage}_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def training_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='train')\n","\n","    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='val')\n","\n","    def test_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='test')"]},{"cell_type":"markdown","metadata":{"id":"t49alRI1z2NC"},"source":["## Training"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014230276,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"qmJYNNj7sN4j"},"outputs":[],"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir ./lightning_logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["7b156f6baa5146f48bedc3b7b77040f6","cc28ff68de5a438098244f4c06261d55","248600bc5895449daf1881c31dbc59f7","9e3c7c77fa644e0f9c96bcac2c9b3afb","f5de1191a0e148ec980ab2a7ca59aadc","aa7879ce50474acaaa5268ae6ce8adbd","7c9fa4ed7c72494f8772bf9fbea846c4","974dd36ec5da4d668837dafb500252f4","109008f349da49b9905d241ad688ac5f","44c207d84dcd42baba74145845a0eaae","cf25700894134e859f3b861825cfbd5b","828595d897f44fe69e29c2b5b7f5d03a","e2ec3d6a189a46e4a3ff8b44b4ffbd7f","d6769dc07c644db3bfd09e23414ae3c2","2875c07472a14c90a3cff89f74627f94","ba96567da16c4100a61bd4d8d0194305","9c54a70e757d428c855909b63d38c605","f2b1ef77bfdb43948ccb1d5b7d5a79b7","3aacf9733f6a462bbd93b726f174a7b4","2c448eb03c3340dfbed25ad427467a91","97f6207712314a23a0d567981c2ac984","9f575a54b0fb4c7f9f4fec8a77e06abf","a587b85218fa427997ac35550f4f2a64","55306708010f4674b24af0e61aeca429","810f8cba8fba4d9bbb730f4791a9f266","e7f69c1faea447ccb7bc3e525e32da93","3352ff05e88a4a09bc2f5e082cda1755","9f70ed05ee694ab199fe4f783439cc88","2e307bcd8dda445d8eb04fc21af6cc7b","e45df65595364c1c8c58d16f743ca421","47dfccf1b5024a7b869650d1456978f4","8f4e666ac3764f45a3f2f453626fbdd8","6b59d72baac847cb8bd03c0888489b2a"]},"executionInfo":{"elapsed":157485,"status":"ok","timestamp":1644014387757,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"2y1QHCUuiSfg","outputId":"a868883b-e8bf-4860-9d79-1ebd0794a5bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n","\n","  | Name      | Type                  | Params\n","----------------------------------------------------\n","0 | criterion | MSELoss               | 0     \n","1 | model     | TimeseriesTransformer | 29.4 M\n","----------------------------------------------------\n","29.4 M    Trainable params\n","0         Non-trainable params\n","29.4 M    Total params\n","117.723   Total estimated model params size (MB)\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  rank_zero_warn(\n","/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  1.07it/s, loss=47.4, v_num=, train_loss_step=47.40, val_loss_step=76.50, val_loss_epoch=76.50, train_loss_epoch=47.40]\n"]}],"source":["# Define parameters for the dataset.\n","# feature_cols = [0,1,2,3]\n","feature_cols = [6]\n","target_cols = [-3]\n","history = 5\n","horizon = 3\n","# split = 0.15\n","split = 0.75\n","batch_size = 64\n","\n","# Create the dataset.\n","dm = BeijingPM25LightningDataModule(\n","    root=dataset_root,\n","    feature_cols=feature_cols,\n","    target_cols=target_cols,\n","    history=history,\n","    horizon=horizon,\n","    split=split,\n","    batch_size=batch_size,\n",")\n","\n","n_input_features: int = len(feature_cols)\n","# n_output_features: int = len(target_cols)\n","n_output_features: int = len(feature_cols)\n","d_time_embed = 6 * n_input_features # Time embedding dimension should be a multiple of the input feature dimension.\n","d_model: int = 512\n","dropout: float = 0.2\n","n_encoder_layers: int = 4\n","n_decoder_layers: int = 4\n","model = BeijingPM25ForecastTransformer(\n","    n_input_features=n_input_features,\n","    n_output_features=n_output_features,\n","    d_time_embed=d_time_embed,\n","    d_model=d_model,\n","    dropout=dropout,\n","    batch_first=True,\n","    n_encoder_layers=n_encoder_layers,\n","    n_decoder_layers=n_decoder_layers,\n","    )\n","\n","kwargs = {}\n","if torch.cuda.is_available():\n","    kwargs['gpus'] = 1\n","\n","\n","TRAIN = True\n","\n","if TRAIN:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        monitor=\"val_loss\",\n","        mode='min',\n","        dirpath=checkpoint_root,\n","        filename='beijing-pm25-transformer-{epoch:02d}-{train_loss:.2f}-{val_loss:.2f}',\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","else:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        dirpath=checkpoint_root,\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","\n","\n","# Devlopment mode.\n","kwargs['fast_dev_run'] = True\n","# kwargs['detect_anomaly'] = True\n","\n","trainer = pl.Trainer(**kwargs)\n","trainer.fit(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"dkCNxcZsjXI9"},"source":["## Testing\n","\n","Here we try to forecast some features and plot them to see how well model does."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Hs3ZpYr1jXI-"},"outputs":[],"source":["# trainer.test(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"_YuL2rAuz5E3"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"OoGeObrywRrl"},"outputs":[],"source":["def evaluate(model: torch.nn.Module, data: torch.Tensor, horizon: int) -> torch.Tensor:\n","\n","    # Prepare output sequence tensor.\n","    if model.batch_first:\n","        dim_batch, dim_seq, dim_feat = data.shape\n","    else:\n","        dim_seq, dim_batch, dim_feat = data.shape\n","    out_seq = torch.empty((dim_batch, 0, dim_feat))\n","\n","    model.eval()\n","    with torch.no_grad():\n","        while True:\n","            # Create decoder input sequence.\n","            # This should start with the last element of the encoder sequence\n","            # and end with the second-to-last element of the target sequence.\n","            if model.batch_first: # Batch dimension first.\n","                tgt = data[:,[-1],:]\n","            else: # Sequence dimension first.\n","                tgt = data[[-1],:,:]\n","\n","            # Pass source and target sequences into the transformer.\n","            y_hat = model(data, tgt)\n","            # print(y_hat.shape)\n","            print('out_seq.shape',out_seq.shape)\n","\n","            # Add predicted value to output sequence.\n","            # out_seq.append(y_hat)\n","            if model.batch_first:\n","                out_seq = torch.cat(\n","                    (out_seq, y_hat),\n","                    dim=1,\n","                )\n","            else:\n","                out_seq = torch.cat(\n","                    (out_seq, y_hat),\n","                    dim=0,\n","                )\n","\n","            # Shift the input and target.\n","            if model.batch_first: # Batch dimension first.\n","                data = torch.cat(\n","                    (data[:,1:,:], y_hat),\n","                    dim=1,\n","                    )\n","            else:\n","                data = torch.cat(\n","                    (data[1:,:,:], y_hat),\n","                    dim=0,\n","                    )\n","\n","            # Check if sequence length has been reached.\n","            seq_len = out_seq.size(1 if model.batch_first else 0)\n","            if seq_len >= horizon:\n","                break\n","\n","    return out_seq"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 5, 1])\n","out_seq.shape torch.Size([1, 0, 1])\n","out_seq.shape torch.Size([1, 1, 1])\n","out_seq.shape torch.Size([1, 2, 1])\n","out_seq.shape torch.Size([1, 3, 1])\n","out_seq tensor([[[ -1.3528],\n","         [ -9.1259],\n","         [-10.0288]]])\n"]},{"name":"stderr","output_type":"stream","text":["/Volumes/GoogleDrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/__pypackages__/3.9/lib/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n","  rank_zero_deprecation(\n"]}],"source":["dm.setup('test')\n","history_x, history_y, horizon_x, horizon_y = dm.dataset_test_wrap[0] # Get first test window.\n","history_x = history_x.unsqueeze(0) # Add batch dimension.\n","history_y = history_y.unsqueeze(0)\n","horizon_x = horizon_x.unsqueeze(0)\n","horizon_y = horizon_y.unsqueeze(0)\n","\n","out_seq = evaluate(\n","    model,\n","    history_x,\n","    horizon,\n","    )"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x12f14e250>"]},"execution_count":32,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Plot the evaluation predictions\n","import matplotlib.pyplot as plt\n","\n","for idx,batch in enumerate(out_seq):\n","    plt.plot(torch.arange(0, history_x.size(1)), history_x[idx], label=f\"X batch {idx}\")\n","    plt.plot(torch.arange(history_x.size(1),history_x.size(1)+batch.size(0)), batch, label=f\"Y batch {idx}\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"transformer_forecast_beijing_pm25.ipynb","provenance":[]},"interpreter":{"hash":"73cda5dbe0541404945d78922515ddeb5c5d95f647b0e783aaf5c1a9a2d741fd"},"kernelspec":{"display_name":"Python 3.9.2 64-bit ('3.9.2': pyenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"109008f349da49b9905d241ad688ac5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"248600bc5895449daf1881c31dbc59f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9fa4ed7c72494f8772bf9fbea846c4","placeholder":"​","style":"IPY_MODEL_aa7879ce50474acaaa5268ae6ce8adbd","value":"Validation sanity check: 100%"}},"2875c07472a14c90a3cff89f74627f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c448eb03c3340dfbed25ad427467a91","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aacf9733f6a462bbd93b726f174a7b4","value":100}},"2c448eb03c3340dfbed25ad427467a91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e307bcd8dda445d8eb04fc21af6cc7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3352ff05e88a4a09bc2f5e082cda1755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b59d72baac847cb8bd03c0888489b2a","placeholder":"​","style":"IPY_MODEL_8f4e666ac3764f45a3f2f453626fbdd8","value":" 43/43 [00:15&lt;00:00,  2.82it/s]"}},"3aacf9733f6a462bbd93b726f174a7b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44c207d84dcd42baba74145845a0eaae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47dfccf1b5024a7b869650d1456978f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55306708010f4674b24af0e61aeca429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6b59d72baac847cb8bd03c0888489b2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b156f6baa5146f48bedc3b7b77040f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_248600bc5895449daf1881c31dbc59f7","IPY_MODEL_9e3c7c77fa644e0f9c96bcac2c9b3afb","IPY_MODEL_f5de1191a0e148ec980ab2a7ca59aadc"],"layout":"IPY_MODEL_cc28ff68de5a438098244f4c06261d55"}},"7c9fa4ed7c72494f8772bf9fbea846c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"810f8cba8fba4d9bbb730f4791a9f266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e307bcd8dda445d8eb04fc21af6cc7b","placeholder":"​","style":"IPY_MODEL_9f70ed05ee694ab199fe4f783439cc88","value":"Validating: 100%"}},"828595d897f44fe69e29c2b5b7f5d03a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6769dc07c644db3bfd09e23414ae3c2","IPY_MODEL_2875c07472a14c90a3cff89f74627f94","IPY_MODEL_ba96567da16c4100a61bd4d8d0194305"],"layout":"IPY_MODEL_e2ec3d6a189a46e4a3ff8b44b4ffbd7f"}},"8f4e666ac3764f45a3f2f453626fbdd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"974dd36ec5da4d668837dafb500252f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97f6207712314a23a0d567981c2ac984":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c54a70e757d428c855909b63d38c605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e3c7c77fa644e0f9c96bcac2c9b3afb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_109008f349da49b9905d241ad688ac5f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_974dd36ec5da4d668837dafb500252f4","value":2}},"9f575a54b0fb4c7f9f4fec8a77e06abf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f70ed05ee694ab199fe4f783439cc88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a587b85218fa427997ac35550f4f2a64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810f8cba8fba4d9bbb730f4791a9f266","IPY_MODEL_e7f69c1faea447ccb7bc3e525e32da93","IPY_MODEL_3352ff05e88a4a09bc2f5e082cda1755"],"layout":"IPY_MODEL_55306708010f4674b24af0e61aeca429"}},"aa7879ce50474acaaa5268ae6ce8adbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba96567da16c4100a61bd4d8d0194305":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f575a54b0fb4c7f9f4fec8a77e06abf","placeholder":"​","style":"IPY_MODEL_97f6207712314a23a0d567981c2ac984","value":" 100/172 [01:03&lt;00:46,  1.56it/s, loss=29.8, v_num=4, train_loss_step=74.20, val_loss_step=163.0, val_loss_epoch=49.50, train_loss_epoch=33.80]"}},"cc28ff68de5a438098244f4c06261d55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cf25700894134e859f3b861825cfbd5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6769dc07c644db3bfd09e23414ae3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b1ef77bfdb43948ccb1d5b7d5a79b7","placeholder":"​","style":"IPY_MODEL_9c54a70e757d428c855909b63d38c605","value":"Epoch 1:  58%"}},"e2ec3d6a189a46e4a3ff8b44b4ffbd7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e45df65595364c1c8c58d16f743ca421":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7f69c1faea447ccb7bc3e525e32da93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_47dfccf1b5024a7b869650d1456978f4","max":43,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e45df65595364c1c8c58d16f743ca421","value":43}},"f2b1ef77bfdb43948ccb1d5b7d5a79b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5de1191a0e148ec980ab2a7ca59aadc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf25700894134e859f3b861825cfbd5b","placeholder":"​","style":"IPY_MODEL_44c207d84dcd42baba74145845a0eaae","value":" 2/2 [00:01&lt;00:00,  1.09it/s]"}}}}},"nbformat":4,"nbformat_minor":0}
