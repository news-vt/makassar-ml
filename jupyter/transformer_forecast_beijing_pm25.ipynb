{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1159,"status":"ok","timestamp":1644014208643,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"hqTzrIYbiSfZ"},"outputs":[],"source":["import os\n","import sys\n","import pathlib\n","import getpass"]},{"cell_type":"markdown","metadata":{"id":"opxQhQ8bzipb"},"source":["## Environment Setup\n","\n","This section checks the runtime environment to see if the notebook is running inside a Google Colab instance. If it is, then it installs the `makassar-ml` package from the GitHub repo and mounts the user's Google Drive folder to the workspace."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644014209277,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"KfK265ryiSfc","outputId":"dd897cb2-a872-4769-85cd-740cc56bee71"},"outputs":[{"name":"stdout","output_type":"stream","text":["IN COLAB\n"]}],"source":["# Detect if running in Google Colab environment.\n","# If so, then clone/install package from GitHub.\n","# Otherwise, use locally.\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print('IN COLAB')\n","\n","except:\n","    IN_COLAB = False\n","    print('NOT IN COLAB')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15271,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"8fT3V4PxzUUM","outputId":"54fd69f1-590f-42f3-ddd8-fc5a5777b0c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Already up to date.\n","Processing ./makassar-ml\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (4.62.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (3.2.2)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (1.5.9)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (0.11.1+cu111)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from makassar-ml==0.1.0) (1.10.0+cu111)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->makassar-ml==0.1.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->makassar-ml==0.1.0) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->makassar-ml==0.1.0) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->makassar-ml==0.1.0) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->makassar-ml==0.1.0) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->makassar-ml==0.1.0) (2018.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (3.10.0.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (6.0)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (2022.1.0)\n","Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (0.3.1)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (0.18.2)\n","Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (59.5.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (2.7.0)\n","Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (0.7.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->makassar-ml==0.1.0) (21.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (3.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.43.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.8.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->makassar-ml==0.1.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->makassar-ml==0.1.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->makassar-ml==0.1.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->makassar-ml==0.1.0) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->makassar-ml==0.1.0) (3.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (1.7.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (2.0.11)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (21.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->makassar-ml==0.1.0) (6.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->makassar-ml==0.1.0) (7.1.2)\n","Building wheels for collected packages: makassar-ml\n","  Building wheel for makassar-ml (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for makassar-ml: filename=makassar_ml-0.1.0-py3-none-any.whl size=6953 sha256=0b17b2a72df9d40a59938391f9a8b4256d19325577dd5a3957b0549e9a56ff32\n","  Stored in directory: /root/.cache/pip/wheels/74/23/8c/5a926f2dd1be9f44af1bf2ca82c4066c5a37ead034a2c97554\n","Successfully built makassar-ml\n","Installing collected packages: makassar-ml\n","  Attempting uninstall: makassar-ml\n","    Found existing installation: makassar-ml 0.1.0\n","    Uninstalling makassar-ml-0.1.0:\n","      Successfully uninstalled makassar-ml-0.1.0\n","Successfully installed makassar-ml-0.1.0\n"]}],"source":["# Install package from GitHub if in Google Drive.\n","if IN_COLAB:\n","    config_path = pathlib.Path('./config.json')\n","    if config_path.exists():\n","        import json\n","        with open(config_path, 'r') as f:\n","            j = json.load(f)\n","        os.environ['GITHUB_TOKEN'] = j['GITHUB_TOKEN']\n","\n","    else:\n","\n","        # Request GitHub access token.\n","        if os.getenv('GITHUB_TOKEN',None) is None:\n","            os.environ['GITHUB_TOKEN'] = getpass.getpass('GitHub Token: ')\n","        else:\n","            print('Using cached GitHub Token')\n","        \n","        import json\n","        with open(config_path, 'w+') as f:\n","            json.dump(\n","                {'GITHUB_TOKEN': os.environ['GITHUB_TOKEN']}, \n","                f,\n","            )\n","\n","    # Clone or update repo.\n","    repo = \"makassar-ml\"\n","    repo_url = f\"https://{os.environ['GITHUB_TOKEN']}@github.com/news-vt/{repo}.git\"\n","    repo_path = f\"/content/{repo}\"\n","    repo_branch = \"develop\"\n","    ![ -d $repo_path ] && git -C $repo_path pull || git clone --branch $repo_branch $repo_url\n","    # !git clone --branch $repo_branch $repo_url\n","\n","    # Install repo to ensure dependencies are resolved.\n","    !pip install --upgrade $repo_path\n","\n","    # Add package location to path.\n","    sys.path.insert(0, repo_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014224545,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Cc2L8BmWiSfc"},"outputs":[],"source":["# Install future annotations for <3.7\n","if sys.version_info < (3,7):\n","    !pip install future-annotations"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3398,"status":"ok","timestamp":1644014227938,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"AjSOQCT5xf5P","outputId":"bb1521a5-fc1b-4d02-d224-61be9fc95ea3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Model save location in Google Drive.\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014227939,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"X-21x9NBxkIV"},"outputs":[],"source":["# Set dataset and model checkpoint root directories.\n","if IN_COLAB:\n","    dataset_root = pathlib.Path(f'/content/gdrive/My Drive/ml/datasets')\n","    checkpoint_root = pathlib.Path(f'/content/gdrive/My Drive/ml/makassar-ml/checkpoints')\n","else:\n","    dataset_root = pathlib.Path('../datasets/')\n","    checkpoint_root = pathlib.Path('../model_checkpoints/')"]},{"cell_type":"markdown","metadata":{"id":"5tN6e7iGzyRO"},"source":["## Model Definitions"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1846,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"GBX0zomgiSfd"},"outputs":[],"source":["from __future__ import annotations\n","import makassar_ml as ml\n","import pytorch_lightning as pl\n","import torch\n","from typing import Optional"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229780,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"02ushc2diSfd"},"outputs":[],"source":["class BeijingPM25LightningDataModule(pl.LightningDataModule):\n","    def __init__(self, \n","        root: str, \n","        feature_cols: list[int], \n","        target_cols: list[int], \n","        history: int, \n","        horizon: int, \n","        split: float,\n","        batch_size: int,\n","        ):\n","        self.root = root\n","        self.feature_cols = feature_cols\n","        self.target_cols = target_cols\n","        self.history = history\n","        self.horizon = horizon\n","        self.split = split\n","        self.batch_size = batch_size\n","\n","    def prepare_data(self):\n","        # Download the dataset.\n","        ml.datasets.BeijingPM25Dataset(\n","            root=self.root,\n","            download=True,\n","            )\n","\n","    def setup(self, stage: Optional[str] = None):\n","\n","        # Create train/val datasets for dataloaders.\n","        if stage == 'fit' or stage is None:\n","            dataset_train_full = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=True,\n","                split=self.split,\n","                )\n","            train_n = len(dataset_train_full)\n","            train_val_cutoff = train_n - round(train_n*.25) # 75% train, 25% val\n","\n","            self.dataset_train = torch.utils.data.Subset(dataset_train_full, list(range(0, train_val_cutoff)))\n","            self.dataset_val = torch.utils.data.Subset(dataset_train_full, list(range(train_val_cutoff, train_n)))\n","\n","            self.dataset_train_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_train,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","            self.dataset_val_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_val,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","        # Create test dataset for dataloaders.\n","        if stage == 'test' or stage is None:\n","            self.dataset_test = ml.datasets.BeijingPM25Dataset(\n","                root=self.root,\n","                download=False,\n","                train=False,\n","                split=self.split,\n","                )\n","            self.dataset_test_wrap = ml.datasets.TimeseriesForecastDatasetWrapper(\n","                dataset=self.dataset_test,\n","                feature_cols=self.feature_cols,\n","                target_cols=self.target_cols,\n","                history=self.history,\n","                horizon=self.horizon,\n","                )\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_train_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_val_wrap,\n","            batch_size=self.batch_size,\n","            )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            dataset=self.dataset_test_wrap,\n","            batch_size=self.batch_size,\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"mwwvwFLxiSfe"},"outputs":[],"source":["# Note that for Transformer decoder target mask,\n","# the `length` parameter is the desired length of\n","# the target sequence.\n","# See docs: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward\n","def create_attn_mask(length: int):\n","    \"\"\"Generate mask used for attention mechanisms.\n","\n","    Masks are a lower-triangular matrix of zeros\n","    with the other entries taking value \"-inf\".\n","\n","    Args:\n","        length (int): Length of square-matrix dimension.\n","\n","    Examples:\n","        >>> create_attn_mask(3)\n","        tensor([[0., -inf, -inf],\n","                [0., 0., -inf],\n","                [0., 0., 0.]])\n","    \"\"\"\n","    # Get lower-triangular matrix of ones.\n","    mask = torch.tril(torch.ones(length, length))\n","\n","    # Replace 0 -> \"-inf\" and 1 -> 0.0\n","    mask = (\n","        mask\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014229781,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"kTNd39bmiSfe"},"outputs":[],"source":["class TimeseriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_input_features: int,\n","        n_output_features: int,\n","        d_time_embed: int,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        n_encoder_layers: int = 4,\n","        n_decoder_layers: int = 4,\n","        n_encoder_heads: int = 8,\n","        n_decoder_heads: int = 8,\n","        ):\n","        super().__init__()\n","\n","        self.batch_first = batch_first\n","\n","        # Time embedding.\n","        self.time_projection = ml.time2vec.Time2Vec(input_dim=n_input_features, embed_dim=d_time_embed)\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=d_time_embed, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_output_features, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=n_encoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=n_decoder_heads, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=n_encoder_layers)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=n_decoder_layers)\n","\n","        # Linear output layer.\n","        # We typically only predict a single data point at a time, so output features is typically 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=n_output_features)\n","\n","    def encode(self, src: torch.Tensor) -> torch.Tensor:\n","\n","        # Embed the source into time-feature dimensions.\n","        x = self.time_projection(src)\n","\n","        # Transform time embedding into arbitrary feature space\n","        # for the attention encoder model.\n","        x = self.encoder_projection(x)\n","\n","        # # Create source mask.\n","        # if self.batch_first:\n","        #     src_length = src.size(1)\n","        # else:\n","        #     src_length = src.size(0)\n","        # src_mask = create_attn_mask(length=src_length).to(device=self.device)\n","\n","        # Pass the linear transformation through the encoder layers.\n","        # x = self.encoder(x, mask=src_mask)\n","        x = self.encoder(x)\n","\n","        return x\n","\n","    def decode(self,\n","        tgt: torch.Tensor,\n","        memory: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        \"\"\"Decode function.\n","\n","        Args:\n","            tgt (torch.Tensor): The sequence to the decoder\n","            memory (torch.Tensor): The sequence from the last layer of the encoder\n","\n","        Returns:\n","            torch.Tensor: Decoded sequence.\n","        \"\"\"\n","        # Transform target into arbitrary feature space.\n","        x = self.decoder_projection(tgt)\n","\n","        # Pass the linear transformation through the decoder layers.\n","        x = self.decoder(tgt=x, memory=memory, tgt_mask=tgt_mask)\n","\n","        # Pass the output of the decoder through the linear prediction layer.\n","        x = self.linear(x)\n","        return x\n","\n","    def forward(self, \n","        src: torch.Tensor,\n","        tgt: torch.Tensor,\n","        tgt_mask: torch.Tensor = None,\n","        ) -> torch.Tensor:\n","        x = self.encode(src)\n","        y = self.decode(tgt=tgt, memory=x, tgt_mask=tgt_mask)\n","        return y"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1644014230275,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"DY6IgfFtiSff"},"outputs":[],"source":["class BeijingPM25ForecastTransformer(pl.LightningModule):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__()\n","        self.criterion = torch.nn.MSELoss(reduction='mean')\n","\n","        # Create the transformer model.\n","        self.model = TimeseriesTransformer(*args, **kwargs)\n","        \n","        # Save parameters for checkpoint.\n","        self.save_hyperparameters()\n","\n","    def forward(self, *args, **kwargs) -> torch.Tensor:\n","        return self.model(*args, **kwargs)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(\n","            self.model.parameters(), \n","            lr=1e-3, \n","            betas=[0.9, 0.98], \n","            eps=1e-9,\n","            )\n","\n","    def compute_loss(self, y_hat, y):\n","        return self.criterion(y_hat, y)\n","\n","    def step(self, batch: torch.Tensor, batch_idx: int, stage: str) -> float:\n","        \"\"\"Generic step function used for train/validation/test loops.\n","\n","        Args:\n","            batch (torch.Tensor): Tensor of batched records.\n","            batch_idx (int): Index of batch relative to entire dataset.\n","            stage (str): Stage key for logging purposes (one of ['train','val','test']).\n","\n","        Returns:\n","            float: Prediction loss.\n","        \"\"\"\n","        history_x, history_y, horizon_x, horizon_y = batch\n","\n","        # Create decoder input sequence.\n","        # This should start with the last element of the encoder sequence\n","        # and end with the second-to-last element of the target sequence.\n","        if self.model.batch_first:\n","            tgt = torch.cat(\n","                (history_x[:,[-1],:], horizon_x[:,:-1,:]),\n","                dim=1,\n","                )\n","        else:\n","            tgt = torch.cat(\n","                (history_x[[-1],:,:], horizon_x[:-1,:,:]),\n","                dim=0,\n","                )\n","        \n","        # Create target attention mask to prevent lookahead cheating.\n","        if self.model.batch_first:\n","            tgt_length = tgt.size(1)\n","        else:\n","            tgt_length = tgt.size(0)\n","        tgt_mask = create_attn_mask(length=tgt_length).to(device=self.device)\n","\n","        # Pass source and target sequences into the transformer.\n","        y_hat = self(history_x, tgt, tgt_mask)\n","\n","        # Compute loss.\n","        # loss = self.compute_loss(y_hat, horizon_y)\n","        loss = self.compute_loss(y_hat, horizon_x)\n","        self.log(f'{stage}_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def training_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='train')\n","\n","    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='val')\n","\n","    def test_step(self, batch: torch.Tensor, batch_idx: int) -> float:\n","        return self.step(batch, batch_idx, stage='test')"]},{"cell_type":"markdown","metadata":{"id":"t49alRI1z2NC"},"source":["## Training"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1644014230276,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"qmJYNNj7sN4j"},"outputs":[],"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir ./lightning_logs"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["7b156f6baa5146f48bedc3b7b77040f6","cc28ff68de5a438098244f4c06261d55","248600bc5895449daf1881c31dbc59f7","9e3c7c77fa644e0f9c96bcac2c9b3afb","f5de1191a0e148ec980ab2a7ca59aadc","aa7879ce50474acaaa5268ae6ce8adbd","7c9fa4ed7c72494f8772bf9fbea846c4","974dd36ec5da4d668837dafb500252f4","109008f349da49b9905d241ad688ac5f","44c207d84dcd42baba74145845a0eaae","cf25700894134e859f3b861825cfbd5b","828595d897f44fe69e29c2b5b7f5d03a","e2ec3d6a189a46e4a3ff8b44b4ffbd7f","d6769dc07c644db3bfd09e23414ae3c2","2875c07472a14c90a3cff89f74627f94","ba96567da16c4100a61bd4d8d0194305","9c54a70e757d428c855909b63d38c605","f2b1ef77bfdb43948ccb1d5b7d5a79b7","3aacf9733f6a462bbd93b726f174a7b4","2c448eb03c3340dfbed25ad427467a91","97f6207712314a23a0d567981c2ac984","9f575a54b0fb4c7f9f4fec8a77e06abf","a587b85218fa427997ac35550f4f2a64","55306708010f4674b24af0e61aeca429","810f8cba8fba4d9bbb730f4791a9f266","e7f69c1faea447ccb7bc3e525e32da93","3352ff05e88a4a09bc2f5e082cda1755","9f70ed05ee694ab199fe4f783439cc88","2e307bcd8dda445d8eb04fc21af6cc7b","e45df65595364c1c8c58d16f743ca421","47dfccf1b5024a7b869650d1456978f4","8f4e666ac3764f45a3f2f453626fbdd8","6b59d72baac847cb8bd03c0888489b2a"]},"executionInfo":{"elapsed":157485,"status":"ok","timestamp":1644014387757,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"2y1QHCUuiSfg","outputId":"a868883b-e8bf-4860-9d79-1ebd0794a5bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name      | Type                  | Params\n","----------------------------------------------------\n","0 | criterion | MSELoss               | 0     \n","1 | model     | TimeseriesTransformer | 29.4 M\n","----------------------------------------------------\n","29.4 M    Trainable params\n","0         Non-trainable params\n","29.4 M    Total params\n","117.723   Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content/gdrive/My Drive/ml/makassar-ml/checkpoints exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b156f6baa5146f48bedc3b7b77040f6","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"828595d897f44fe69e29c2b5b7f5d03a","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a587b85218fa427997ac35550f4f2a64","version_major":2,"version_minor":0},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["# Define parameters for the dataset.\n","# feature_cols = [0,1,2,3]\n","feature_cols = [6]\n","target_cols = [-3]\n","history = 5\n","horizon = 3\n","# split = 0.15\n","split = 0.75\n","batch_size = 64\n","\n","# Create the dataset.\n","dm = BeijingPM25LightningDataModule(\n","    root=dataset_root,\n","    feature_cols=feature_cols,\n","    target_cols=target_cols,\n","    history=history,\n","    horizon=horizon,\n","    split=split,\n","    batch_size=batch_size,\n",")\n","\n","n_input_features: int = len(feature_cols)\n","# n_output_features: int = len(target_cols)\n","n_output_features: int = len(feature_cols)\n","d_time_embed = 6 * n_input_features # Time embedding dimension should be a multiple of the input feature dimension.\n","d_model: int = 512\n","dropout: float = 0.2\n","n_encoder_layers: int = 4\n","n_decoder_layers: int = 4\n","model = BeijingPM25ForecastTransformer(\n","    n_input_features=n_input_features,\n","    n_output_features=n_output_features,\n","    d_time_embed=d_time_embed,\n","    d_model=d_model,\n","    dropout=dropout,\n","    batch_first=True,\n","    n_encoder_layers=n_encoder_layers,\n","    n_decoder_layers=n_decoder_layers,\n","    )\n","\n","kwargs = {}\n","if torch.cuda.is_available():\n","    kwargs['gpus'] = 1\n","\n","\n","TRAIN = True\n","\n","if TRAIN:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        monitor=\"val_loss\",\n","        mode='min',\n","        dirpath=checkpoint_root,\n","        filename='beijing-pm25-transformer-{epoch:02d}-{train_loss:.2f}-{val_loss:.2f}',\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","else:\n","    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","        dirpath=checkpoint_root,\n","    )\n","    kwargs['callbacks'] = [checkpoint_callback]\n","\n","\n","# Devlopment mode.\n","kwargs['fast_dev_run'] = True\n","# kwargs['detect_anomaly'] = True\n","\n","trainer = pl.Trainer(**kwargs)\n","trainer.fit(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"dkCNxcZsjXI9"},"source":["## Testing\n","\n","Here we try to forecast some features and plot them to see how well model does."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"Hs3ZpYr1jXI-"},"outputs":[],"source":["# trainer.test(model, dm)"]},{"cell_type":"markdown","metadata":{"id":"_YuL2rAuz5E3"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644014387758,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":300},"id":"OoGeObrywRrl"},"outputs":[],"source":["def evaluate(model: torch.nn.Module, data: torch.Tensor, horizon: int) -> torch.Tensor:\n","    model.eval()\n","\n","    out_seq = []\n","    with torch.no_grad():\n","        \n","        while len(out_seq) < horizon:\n","            # Create decoder input sequence.\n","            # This should start with the last element of the encoder sequence\n","            # and end with the second-to-last element of the target sequence.\n","            if model.batch_first: # Batch dimension first.\n","                tgt = data[:,[-1],:]\n","            else: # Sequence dimension first.\n","                tgt = data[[-1],:,:]\n","\n","            # Pass source and target sequences into the transformer.\n","            y_hat = model(data, tgt)\n","\n","            # Add predicted value to output sequence.\n","            out_seq.append(y_hat)\n","\n","            # Shift the input and target.\n","            if model.batch_first: # Batch dimension first.\n","                data = torch.cat(\n","                    (data[:,1:,:], y_hat),\n","                    dim=1,\n","                    )\n","            else:\n","                data = torch.cat(\n","                    (data[1:,:,:], y_hat),\n","                    dim=0,\n","                    )\n","    return out_seq"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"transformer_forecast_beijing_pm25.ipynb","provenance":[]},"interpreter":{"hash":"73cda5dbe0541404945d78922515ddeb5c5d95f647b0e783aaf5c1a9a2d741fd"},"kernelspec":{"display_name":"Python 3.9.2 64-bit ('3.9.2': pyenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"109008f349da49b9905d241ad688ac5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"248600bc5895449daf1881c31dbc59f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9fa4ed7c72494f8772bf9fbea846c4","placeholder":"​","style":"IPY_MODEL_aa7879ce50474acaaa5268ae6ce8adbd","value":"Validation sanity check: 100%"}},"2875c07472a14c90a3cff89f74627f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c448eb03c3340dfbed25ad427467a91","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aacf9733f6a462bbd93b726f174a7b4","value":100}},"2c448eb03c3340dfbed25ad427467a91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e307bcd8dda445d8eb04fc21af6cc7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3352ff05e88a4a09bc2f5e082cda1755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b59d72baac847cb8bd03c0888489b2a","placeholder":"​","style":"IPY_MODEL_8f4e666ac3764f45a3f2f453626fbdd8","value":" 43/43 [00:15&lt;00:00,  2.82it/s]"}},"3aacf9733f6a462bbd93b726f174a7b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44c207d84dcd42baba74145845a0eaae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47dfccf1b5024a7b869650d1456978f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55306708010f4674b24af0e61aeca429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"6b59d72baac847cb8bd03c0888489b2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b156f6baa5146f48bedc3b7b77040f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_248600bc5895449daf1881c31dbc59f7","IPY_MODEL_9e3c7c77fa644e0f9c96bcac2c9b3afb","IPY_MODEL_f5de1191a0e148ec980ab2a7ca59aadc"],"layout":"IPY_MODEL_cc28ff68de5a438098244f4c06261d55"}},"7c9fa4ed7c72494f8772bf9fbea846c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"810f8cba8fba4d9bbb730f4791a9f266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e307bcd8dda445d8eb04fc21af6cc7b","placeholder":"​","style":"IPY_MODEL_9f70ed05ee694ab199fe4f783439cc88","value":"Validating: 100%"}},"828595d897f44fe69e29c2b5b7f5d03a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6769dc07c644db3bfd09e23414ae3c2","IPY_MODEL_2875c07472a14c90a3cff89f74627f94","IPY_MODEL_ba96567da16c4100a61bd4d8d0194305"],"layout":"IPY_MODEL_e2ec3d6a189a46e4a3ff8b44b4ffbd7f"}},"8f4e666ac3764f45a3f2f453626fbdd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"974dd36ec5da4d668837dafb500252f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97f6207712314a23a0d567981c2ac984":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c54a70e757d428c855909b63d38c605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e3c7c77fa644e0f9c96bcac2c9b3afb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_109008f349da49b9905d241ad688ac5f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_974dd36ec5da4d668837dafb500252f4","value":2}},"9f575a54b0fb4c7f9f4fec8a77e06abf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f70ed05ee694ab199fe4f783439cc88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a587b85218fa427997ac35550f4f2a64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810f8cba8fba4d9bbb730f4791a9f266","IPY_MODEL_e7f69c1faea447ccb7bc3e525e32da93","IPY_MODEL_3352ff05e88a4a09bc2f5e082cda1755"],"layout":"IPY_MODEL_55306708010f4674b24af0e61aeca429"}},"aa7879ce50474acaaa5268ae6ce8adbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba96567da16c4100a61bd4d8d0194305":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f575a54b0fb4c7f9f4fec8a77e06abf","placeholder":"​","style":"IPY_MODEL_97f6207712314a23a0d567981c2ac984","value":" 100/172 [01:03&lt;00:46,  1.56it/s, loss=29.8, v_num=4, train_loss_step=74.20, val_loss_step=163.0, val_loss_epoch=49.50, train_loss_epoch=33.80]"}},"cc28ff68de5a438098244f4c06261d55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cf25700894134e859f3b861825cfbd5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6769dc07c644db3bfd09e23414ae3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b1ef77bfdb43948ccb1d5b7d5a79b7","placeholder":"​","style":"IPY_MODEL_9c54a70e757d428c855909b63d38c605","value":"Epoch 1:  58%"}},"e2ec3d6a189a46e4a3ff8b44b4ffbd7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e45df65595364c1c8c58d16f743ca421":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7f69c1faea447ccb7bc3e525e32da93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_47dfccf1b5024a7b869650d1456978f4","max":43,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e45df65595364c1c8c58d16f743ca421","value":43}},"f2b1ef77bfdb43948ccb1d5b7d5a79b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5de1191a0e148ec980ab2a7ca59aadc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf25700894134e859f3b861825cfbd5b","placeholder":"​","style":"IPY_MODEL_44c207d84dcd42baba74145845a0eaae","value":" 2/2 [00:01&lt;00:00,  1.09it/s]"}}}}},"nbformat":4,"nbformat_minor":0}
