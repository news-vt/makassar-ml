{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"colab":{"name":"model_playground.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fsJRsGVE-2P_"},"source":["# Model Playground\n","\n","Sources:\n","- Time-series Transformer guide: <https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3>\n","- Time2Vec embedding: <https://arxiv.org/pdf/1907.05321.pdf>"]},{"cell_type":"code","metadata":{"id":"jyKBALklEHiJ","executionInfo":{"status":"ok","timestamp":1633493727757,"user_tz":240,"elapsed":146,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-bMu_Vu_acg"},"source":["## Load Datasets"]},{"cell_type":"code","metadata":{"id":"UOQoJZP9-2QD","executionInfo":{"status":"ok","timestamp":1633493727912,"user_tz":240,"elapsed":5,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjx52UOW_W-I","executionInfo":{"status":"ok","timestamp":1633493727913,"user_tz":240,"elapsed":5,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"636c7120-f9e8-4f8e-b4fa-a4b02463095b"},"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\")\n","    dataset_root = \"/content/gdrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/datasets/\"\n","else:\n","    dataset_root = \"../datasets/\""],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"2z1TdKbcEm1z"},"source":["### Dataset: Beijing PM2.5"]},{"cell_type":"code","metadata":{"id":"H_gI0qnYwI0y","executionInfo":{"status":"ok","timestamp":1633493727913,"user_tz":240,"elapsed":3,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import torch.utils.data"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"005fJqGhEPPZ","executionInfo":{"status":"ok","timestamp":1633493727914,"user_tz":240,"elapsed":4,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["class BeijingPM25Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, path: str):\n","\n","        # Read the input file.\n","        fields = ['year','month','day','hour','DEWP','TEMP','PRES','Is','Ir'] # Specific columns to use.\n","        self.df = pd.read_csv(path, usecols=fields)\n","\n","        # # Create single date column from independent year/month/day columns.\n","        # self.df = self.df.assign(date=pd.to_datetime(df[['year','month','day','hour']]))\n","\n","        # Add health scores to the dataset for specific plants.\n","        # These scores are normalized between [0,1].\n","        features = ['tomato', 'sunflower', 'cucumber']\n","        self.df = self.df.assign(**{feat:np.random.uniform(0.0, 1.0, size=self.df.shape[0]) for feat in features})\n","\n","        # Separate dataset into source (input) and target (output).\n","        # self.src = df[['date', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        self.src = self.df[['year','month','day','hour', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        self.tgt = self.df[['tomato', 'sunflower', 'cucumber']].to_numpy()\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        src = self.src[index]\n","        tgt = self.tgt[index]\n","        return src, tgt"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"dinxQl1IwZ-H","executionInfo":{"status":"ok","timestamp":1633493728043,"user_tz":240,"elapsed":132,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Load the dataset from file.\n","csvfile = os.path.join(dataset_root, \"beijing_pm2.5\", \"PRSA_data_2010.1.1-2014.12.31.csv\")\n","dataset = BeijingPM25Dataset(csvfile)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLb4BoQcxtkY","executionInfo":{"status":"ok","timestamp":1633493728043,"user_tz":240,"elapsed":3,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Create a dataset loader to assist with batching.\n","loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KqI9yLsvGhJu"},"source":["## Model Definition"]},{"cell_type":"code","metadata":{"id":"28u0APtCGjqj","executionInfo":{"status":"ok","timestamp":1633493728043,"user_tz":240,"elapsed":3,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import torch.nn"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0u-z53OhXWCC"},"source":["#### Transformer for Time-Series Forecasting"]},{"cell_type":"code","metadata":{"id":"rbndVAAOGnsN","executionInfo":{"status":"ok","timestamp":1633493728044,"user_tz":240,"elapsed":4,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["class TimeSeriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_encoder_inputs: int,\n","        n_decoder_inputs: int,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        ):\n","        super().__init__()\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=n_encoder_inputs, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_decoder_inputs, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=8)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=8)\n","\n","        # Linear output layer.\n","        # We only predict a single data point at a time, so output features is 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=1)\n","\n","\n","    def encode(self, src):\n","        pass\n","\n","\n","    def decode(self, tgt, memory):\n","        pass\n","\n","\n","    def forward(self, src, tgt):\n","        x = self.encode(src)\n","        x = self.decode(tgt=tgt, memory=x)\n","        return x"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZ198-xWmAyv","executionInfo":{"status":"ok","timestamp":1633493728457,"user_tz":240,"elapsed":416,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Prediction problem setup.\n","#\n","# Given 24 hours of data points, predict the next 1 hour of data points.\n","n_encoder_inputs = 24 # Number of data points in input sequence.\n","n_decoder_inputs = 1 # Number of data points in output sequence.\n","\n","d_model = 512 # Latent dimension.\n","dropout = 0.1\n","\n","# Create new model.\n","model = TimeSeriesTransformer(\n","    n_encoder_inputs,\n","    n_decoder_inputs,\n","    d_model,\n","    dropout,\n",")"],"execution_count":21,"outputs":[]}]}