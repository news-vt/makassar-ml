{"cells":[{"cell_type":"markdown","metadata":{"id":"fsJRsGVE-2P_"},"source":["# Model Playground\n","\n","Sources:\n","- Time-series Transformer guide: <https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3>\n","- Time2Vec embedding: <https://arxiv.org/pdf/1907.05321.pdf>"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":117,"status":"ok","timestamp":1635977723730,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"jyKBALklEHiJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","from typing import List"]},{"cell_type":"markdown","metadata":{"id":"KqI9yLsvGhJu"},"source":["## Model Definition"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1088,"status":"ok","timestamp":1635977725002,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"Hei232q2zhIk"},"outputs":[],"source":["import torch\n","import torch.nn"]},{"cell_type":"markdown","metadata":{"id":"0u-z53OhXWCC"},"source":["### Transformer for Time-Series Forecasting"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635977725003,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"7pqfmWgrR28-"},"outputs":[],"source":["def create_attn_mask(length: int, device: str = None):\n","    \"\"\"Generate mask used for attention mechanisms.\n","\n","    Masks are a lower-triangular matrix of zeros\n","    with the other entries taking value \"-inf\".\n","\n","    Args:\n","        length (int): Length of square-matrix dimension.\n","        device (str, optional): PyTorch device.\n","\n","    Examples:\n","\n","        >>> create_mask(3)\n","        tensor([[0., -inf, -inf],\n","                [0., 0., -inf],\n","                [0., 0., 0.]])\n","    \"\"\"\n","    # Get lower-triangular matrix of ones.\n","    mask = torch.tril(torch.ones(length, length, device=device))\n","\n","    # Replace 0 -> \"-inf\" and 1 -> 0.0\n","    mask = (\n","        mask\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1635977725003,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"rbndVAAOGnsN"},"outputs":[],"source":["class TimeSeriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_encoder_inputs: int,\n","        n_decoder_inputs: int,\n","        n_outputs: int = 1,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        ):\n","        super().__init__()\n","\n","        self.batch_first = batch_first\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=n_encoder_inputs, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_decoder_inputs, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=8)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=8)\n","\n","        # Linear output layer.\n","        # We typically only predict a single data point at a time, so output features is typically 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=n_outputs)\n","\n","\n","    def encode(self, src):\n","        # Transform source into arbitrary feature space.\n","        x = self.encoder_projection(src)\n","\n","        # # Create source mask.\n","        # if self.batch_first:\n","        #     src_length, batch_size = src.size(1), src.size(0)\n","        # else:\n","        #     src_length, batch_size = src.size(0), src.size(1)\n","        # src_mask = create_attn_mask(length=src_length, device=src.device)\n","\n","        # # Pass the linear transformation through the encoder layers.\n","        # x = self.encoder(x, mask=src_mask)\n","        x = self.encoder(x)\n","\n","        return x\n","\n","\n","    def decode(self, tgt, memory):\n","        # Transform target into arbitrary feature space.\n","        x = self.decoder_projection(tgt)\n","\n","        # Create target attention mask.\n","        if self.batch_first:\n","            tgt_length, batch_size = tgt.size(1), tgt.size(0)\n","        else:\n","            tgt_length, batch_size = tgt.size(0), tgt.size(1)\n","        tgt_mask = create_attn_mask(length=tgt_length, device=tgt.device)\n","\n","        # Pass the linear transformation through the decoder layers.\n","        x = self.decoder(tgt=x, memory=memory, tgt_mask=tgt_mask)\n","\n","        # Pass the output of the decoder through the linear prediction layer.\n","        x = self.linear(x)\n","\n","        return x\n","\n","\n","    def forward(self, x):\n","        src, tgt = x\n","        y = self.encode(src)\n","        y = self.decode(tgt=tgt, memory=y)\n","        return y\n","\n","    \n","    def step(self, batch):\n","        src, tgt_int, tgt_out = batch"]},{"cell_type":"markdown","metadata":{"id":"c-bMu_Vu_acg"},"source":["## Load Dataset: Beijing PM2.5 "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1635977725199,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"H_gI0qnYwI0y"},"outputs":[],"source":["import torch.utils.data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977725199,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"UOQoJZP9-2QD"},"outputs":[],"source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977725199,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"jjx52UOW_W-I","outputId":"fa06eb75-a843-4bd9-9015-82cce75899d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\")\n","    dataset_root = \"/content/gdrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/datasets/\"\n","else:\n","    dataset_root = \"../datasets/\""]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635977725199,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"005fJqGhEPPZ"},"outputs":[],"source":["class BeijingPM25Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, path: str):\n","\n","        # Read the input file.\n","        fields = ['year','month','day','hour','DEWP','TEMP','PRES','Is','Ir'] # Specific columns to use.\n","        self.df = pd.read_csv(path, usecols=fields)\n","\n","        # # Create single date column from independent year/month/day columns.\n","        # self.df = self.df.assign(date=pd.to_datetime(df[['year','month','day','hour']]))\n","\n","        # Add health scores to the dataset for specific plants.\n","        # These scores are normalized between [0,1].\n","        features = ['tomato', 'sunflower', 'cucumber']\n","        self.df = self.df.assign(**{feat:np.random.uniform(0.0, 1.0, size=self.df.shape[0]) for feat in features})\n","\n","        # Separate dataset into source (input) and target (output).\n","        # self.src = df[['date', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        # self.src = self.df[['year','month','day','hour', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        #\n","        # self.src = self.df[['DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        # self.tgt = self.df[['tomato', 'sunflower', 'cucumber']].to_numpy()\n","        #\n","        # self.data = self.df[['DEWP', 'TEMP', 'PRES', 'Is', 'Ir','tomato', 'sunflower', 'cucumber']].to_numpy()\n","        self.src = self.df[['DEWP']].to_numpy()\n","        self.tgt = self.df[['tomato']].to_numpy()\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        src = torch.tensor(self.src[index], dtype=torch.float)\n","        tgt = torch.tensor(self.tgt[index], dtype=torch.float)\n","        return src, tgt\n","        # return torch.tensor(self.data[index], dtype=torch.float)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1635977725200,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"5w5LqiF9Xs6N"},"outputs":[],"source":["class BeijingSlidingWindowDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataset: torch.utils.data.Dataset, window_size: int, horizon_size: int):\n","        self.window_size = window_size\n","        self.horizon_size = horizon_size\n","\n","        # Split original dataset into windows.\n","        self.src_in, self.src_out = [], []\n","        self.tgt_in, self.tgt_out = [], []\n","        for i in range(0, len(dataset), horizon_size):\n","            src_in, tgt_in = dataset[i:i+window_size]\n","            src_out, tgt_out = dataset[i+window_size:i+window_size+horizon_size]\n","            self.src_in.append(src_in)\n","            self.src_out.append(src_out)\n","            self.tgt_in.append(tgt_in)\n","            self.tgt_out.append(tgt_out)\n","        # windows = [\n","        #     (\n","        #         dataset[i:i+window_size],\n","        #         dataset[i+window_size:i+window_size+horizon_size],\n","        #     ) \n","        #     for i in range(0, len(dataset), horizon_size)\n","        # ]\n","        # self.n_windows = len(windows)\n","        # self.src, self.tgt = tuple(zip(*windows))\n","        #\n","        # self.src_in = torch.stack(self.src_in, dim=0)\n","        # self.src_out = torch.stack(self.src_out, dim=0)\n","        # self.tgt_in = torch.stack(self.tgt_in, dim=0)\n","        # self.tgt_out = torch.stack(self.tgt_out, dim=0)\n","\n","        # Pad any partial sequences.\n","        self.src_in = torch.nn.utils.rnn.pad_sequence(self.src_in, batch_first=True, padding_value=0.0)\n","        self.src_out = torch.nn.utils.rnn.pad_sequence(self.src_out, batch_first=True, padding_value=0.0)\n","        self.tgt_in = torch.nn.utils.rnn.pad_sequence(self.tgt_in, batch_first=True, padding_value=0.0)\n","        self.tgt_out = torch.nn.utils.rnn.pad_sequence(self.tgt_out, batch_first=True, padding_value=0.0)\n","\n","    def __len__(self):\n","        return self.src_in.shape[0]\n","    \n","    def __getitem__(self, index):\n","        return self.src_in[index], self.tgt_in[index], self.src_out[index], self.tgt_out[index]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1635977725200,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"WVM-HY9iY8Bd"},"outputs":[],"source":["class NewBeijingSlidingWindowDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataset: torch.utils.data.Dataset, window_size: int):\n","        self.window_size = window_size\n","\n","        # Split original dataset into windows.\n","        self.src, self.tgt = [], []\n","        for i in range(0, len(dataset)):\n","            src, tgt = dataset[i:i+window_size]\n","            self.src.append(src)\n","            self.tgt.append(tgt)\n","\n","        # Pad any partial sequences.\n","        self.src = torch.nn.utils.rnn.pad_sequence(self.src, batch_first=True, padding_value=0.0)\n","        self.tgt = torch.nn.utils.rnn.pad_sequence(self.tgt, batch_first=True, padding_value=0.0)\n","\n","    def __len__(self):\n","        return self.src.shape[0]\n","    \n","    def __getitem__(self, index):\n","        return self.src[index], self.tgt[index]"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1635977725344,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"dinxQl1IwZ-H"},"outputs":[],"source":["# Load the dataset from file.\n","csvfile = os.path.join(dataset_root, \"beijing_pm2.5\", \"PRSA_data_2010.1.1-2014.12.31.csv\")\n","dataset = BeijingPM25Dataset(csvfile)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1635977725345,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"o8VgCcFLpuLB"},"outputs":[],"source":["# Create train/test split.\n","trainsplit = 0.75\n","n_records = len(dataset)\n","split_idx = int(n_records*trainsplit)\n","train_dataset = torch.utils.data.Subset(dataset, list(range(split_idx)))\n","test_dataset = torch.utils.data.Subset(dataset, list(range(split_idx, n_records)))"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1748,"status":"ok","timestamp":1635977727091,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"j6c3khi9dERz"},"outputs":[],"source":["# Create sliding window dataset.\n","window_size = 24 # Number of historic data points.\n","horizon_size = 5 # Number of prediction points in the future.\n","# swdataset = BeijingSlidingWindowDataset(dataset, window_size=window_size, horizon_size=horizon_size)\n","train_windows = NewBeijingSlidingWindowDataset(train_dataset, window_size=window_size)\n","test_windows = NewBeijingSlidingWindowDataset(test_dataset, window_size=window_size)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977727091,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"wLb4BoQcxtkY"},"outputs":[],"source":["# Create a dataset loader to assist with batching.\n","batch_size = 32\n","train_loader = torch.utils.data.DataLoader(train_windows, batch_size=batch_size, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_windows, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977727092,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"hs8FUBMsckPh"},"outputs":[],"source":["# Create start-of-sequence (SOS) vector.\n","sos_vector = torch.ones(dataset.tgt.shape[-1])*-1.0"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977727092,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"T5AJ6-fRcTWD"},"outputs":[],"source":["# # Test the data loader.\n","# for b,batch in enumerate(loader):\n","#     src_in,tgt_in, src_out,tgt_out = batch\n","#     print(src_out[0,0],tgt_out[0,0])\n","#     print(dataset[24])\n","#     print(f'[{b}] src_in.shape',src_in.shape)\n","#     print(f'[{b}] tgt_in.shape',tgt_in.shape)\n","#     print(f'[{b}] src_out.shape',src_out.shape)\n","#     print(f'[{b}] tgt_out.shape',tgt_out.shape)\n","#     break"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635977727092,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"veSDg-VIZlXJ"},"outputs":[],"source":["# # Test the data loader.\n","# for b,batch in enumerate(train_loader):\n","#     src,tgt = batch\n","#     print(src[0,0],tgt[0,0])\n","#     print(dataset[0])\n","#     print(f'[{b}] src.shape',src.shape)\n","#     print(f'[{b}] tgt.shape',tgt.shape)\n","#     break"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1635977727092,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"cOIPbbcCoCCQ"},"outputs":[],"source":["# a = torch.ones(23,8)\n","# b = torch.ones(24,8)\n","# pad = (0,0,1,1)\n","# # print(a.view((24,8)).shape)\n","# print(torch.nn.functional.pad(a, pad).shape)\n","# print(torch.nn.functional.pad(b, pad).shape)\n","# print(torch.nn.utils.rnn.pad_sequence([a,b], batch_first=True, padding_value=0.0)[0,-1])"]},{"cell_type":"markdown","metadata":{"id":"6y4_vFPuz4gA"},"source":["## Training"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977727093,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"A6TinrjD4KXP"},"outputs":[],"source":["import time\n","from contextlib import contextmanager\n","@contextmanager\n","def timing(description='Elapsed time'):\n","    \"\"\"Context manager to print elapsed time from call.\"\"\"\n","    start_time = time.time()\n","    yield\n","    stop_time = time.time()\n","    print(f\"{description}: {stop_time - start_time} seconds\")"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1635977727093,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"6eh02oDKfHam"},"outputs":[],"source":["def smape_loss(y: torch.Tensor, y_pred: torch.Tensor):\n","    return 2*(y - y_pred).abs() / (y.abs() + y_pred.abs())"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1635977727258,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"oTZVQWn1z57P"},"outputs":[],"source":["def train(model, loader, optimizer, criterion, epochs, device='cpu') -> List[float]:\n","    model.train() # Turn on training mode.\n","\n","    losses = []\n","    for e in range(epochs):\n","        running_loss = 0.0\n","        for i, batch in enumerate(loader):\n","            # inputs, targets = batch # Unpack the batch tuple.\n","            # src_in,tgt_in,_,tgt_out = batch\n","            src,tgt = batch\n","            \n","            # Send data to device.\n","            # src_in = src_in.to(device)\n","            # tgt_in = tgt_in.to(device)\n","            # tgt_out = tgt_out.to(device)\n","            src = src.to(device)\n","            tgt = tgt.to(device)\n","\n","            # Shift target sequences so that SOS vector can be inserted.\n","            sos_batch = sos_vector.view(1,1,sos_vector.size(0)).repeat(tgt.shape[0],1,1)\n","            tgt_shifted = torch.cat((sos_batch, tgt[:, :-2]), dim=1)\n","            tgt_y = tgt[:, 1:]\n","\n","\n","            # Evaluate the model.\n","            # tgt_pred = model((src_in,tgt_in))\n","            tgt_pred = model((src, tgt_shifted))\n","            # tgt_pred = model((src[:, :-1], tgt_in))\n","\n","            print('tgt.shape',tgt.shape)\n","            print('tgt_y.shape',tgt_y.shape)\n","            print('sos_vector.shape',sos_vector.shape)\n","            print('sos_batch.shape', sos_batch.shape)\n","            print('tgt_shifted.shape', tgt_shifted.shape)\n","            print('tgt_pred.shape', tgt_pred.shape)\n","            print()\n","            # print(tgt_pred.view(-1, tgt_out.shape[-1]).shape)\n","            # print(tgt_out.view(-1, tgt_out.shape[-1]).shape)\n","            # print('inputs.shape',inputs.shape)\n","            # print('targets.shape',targets.shape)\n","            # print('targets_pred.shape',targets_pred.shape)\n","\n","            # Compute losses.\n","            loss = criterion(tgt_pred, tgt_y)\n","\n","            # Zero the gradient, back-propagate, and step the optimizer.\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Accumulate the loss for this epoch.\n","            running_loss += loss.item()\n","            if i >= 2: break\n","\n","        # Report epoch results.\n","        print(f'Epoch {e}: loss {running_loss}')\n","        losses.append(losses)\n","    return losses"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18005,"status":"ok","timestamp":1635977745262,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"tZ198-xWmAyv","outputId":"410ea245-5c5b-455b-a1f9-b93d2ed4fb60"},"outputs":[{"name":"stdout","output_type":"stream","text":["tgt.shape torch.Size([32, 24, 1])\n","tgt_y.shape torch.Size([32, 23, 1])\n","sos_vector.shape torch.Size([1])\n","sos_batch.shape torch.Size([32, 1, 1])\n","tgt_shifted.shape torch.Size([32, 23, 1])\n","tgt_pred.shape torch.Size([32, 23, 1])\n","\n","tgt.shape torch.Size([32, 24, 1])\n","tgt_y.shape torch.Size([32, 23, 1])\n","sos_vector.shape torch.Size([1])\n","sos_batch.shape torch.Size([32, 1, 1])\n","tgt_shifted.shape torch.Size([32, 23, 1])\n","tgt_pred.shape torch.Size([32, 23, 1])\n","\n","tgt.shape torch.Size([32, 24, 1])\n","tgt_y.shape torch.Size([32, 23, 1])\n","sos_vector.shape torch.Size([1])\n","sos_batch.shape torch.Size([32, 1, 1])\n","tgt_shifted.shape torch.Size([32, 23, 1])\n","tgt_pred.shape torch.Size([32, 23, 1])\n","\n","Epoch 0: loss 106.95018434524536\n","Elapsed time: 17.702310800552368 seconds\n"]}],"source":["# Set runtime device.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Prediction problem setup.\n","#\n","# Given 24 hours of data points, predict the next 1 hour of data points.\n","n_encoder_inputs = 1 #24 # Number of data points in input sequence.\n","n_decoder_inputs = 1 #8 # Number of data points in output sequence.\n","n_outputs = 1 # Number of output data points.\n","\n","d_model = 512 # Latent dimension.\n","dropout = 0.1\n","\n","# Create new model.\n","model = TimeSeriesTransformer(\n","    n_encoder_inputs,\n","    n_decoder_inputs,\n","    n_outputs,\n","    d_model,\n","    dropout,\n","    batch_first=True,\n",")\n","\n","# Train the model.\n","# Display training time too.\n","epochs = 1\n","lr = 1e-3\n","with timing():\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = torch.nn.MSELoss(reduction='mean')\n","    train(model, loader=train_loader, optimizer=optimizer, criterion=criterion, epochs=epochs, device=device)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":119,"status":"error","timestamp":1635978610907,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"GyElH3Vt339I","outputId":"5e624872-5dc4-471c-b104-adfe18908c40"},"outputs":[{"ename":"IndentationError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-ace986ad3734>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    out = model((history, sos))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}],"source":["def evaluate(model, history, horizon, device='cpu'):\n","    model.eval()\n","    model.to(device)\n","\n","    # sos = sos_vector.view(1,1,sos_vector.size(0))\n","    sos = sos_vector.view(1,1,sos_vector.size(0)).repeat(history.shape[0],1,1)\n","    for i in range(horizon):\n","        out = model((history, sos))\n","    print('out.shape', out.shape)\n","    return out"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1635978964205,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"},"user_tz":240},"id":"iih3V9e85QQY","outputId":"8744ad7f-c30d-4ae1-8981-cbfdcaba7e99"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 24, 1]) torch.Size([32, 24, 1]) torch.Size([1, 24, 1])\n","out.shape torch.Size([1, 1, 1])\n","torch.Size([1, 1, 1])\n","tensor([[[1.1928],\n","         [1.8505],\n","         [1.5840],\n","         [1.7564],\n","         [1.8933],\n","         [1.6984],\n","         [1.8085],\n","         [1.5899],\n","         [1.1856],\n","         [1.4727],\n","         [1.5721],\n","         [1.9533],\n","         [1.9637],\n","         [1.4715],\n","         [1.8771],\n","         [1.1999],\n","         [1.8688],\n","         [1.6952],\n","         [1.5914],\n","         [1.2477],\n","         [1.2189],\n","         [1.7047],\n","         [1.9770],\n","         [1.9383]]], grad_fn=<DivBackward0>)\n"]}],"source":["for batch in test_loader:\n","    src, tgt = batch\n","    for i in range(src.shape[0]):\n","        print(src.shape, tgt.shape, src[i].view(1,*src.shape[1:]).shape)\n","        out = evaluate(model, src[i].view(1,*src.shape[1:]), 5, device=device)\n","        print(out.shape)\n","        print(smape_loss(out, tgt[i]))\n","        break\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VM0Lu6hp58-8"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"model_playground.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
