{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"colab":{"name":"model_playground.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fsJRsGVE-2P_"},"source":["# Model Playground\n","\n","Sources:\n","- Time-series Transformer guide: <https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3>\n","- Time2Vec embedding: <https://arxiv.org/pdf/1907.05321.pdf>"]},{"cell_type":"code","metadata":{"id":"jyKBALklEHiJ","executionInfo":{"status":"ok","timestamp":1634593886736,"user_tz":240,"elapsed":164,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd"],"execution_count":113,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-bMu_Vu_acg"},"source":["## Load Datasets"]},{"cell_type":"code","metadata":{"id":"UOQoJZP9-2QD","executionInfo":{"status":"ok","timestamp":1634593886887,"user_tz":240,"elapsed":7,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"execution_count":114,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjx52UOW_W-I","executionInfo":{"status":"ok","timestamp":1634593886888,"user_tz":240,"elapsed":8,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"c288f29a-3e25-4d91-cac7-d5e6be4c2506"},"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount(\"/content/gdrive\")\n","    dataset_root = \"/content/gdrive/My Drive/Virginia Tech/graduate/research/makassar/repos/makassar-ml/datasets/\"\n","else:\n","    dataset_root = \"../datasets/\""],"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"2z1TdKbcEm1z"},"source":["### Dataset: Beijing PM2.5"]},{"cell_type":"code","metadata":{"id":"H_gI0qnYwI0y","executionInfo":{"status":"ok","timestamp":1634593886888,"user_tz":240,"elapsed":6,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import torch.utils.data"],"execution_count":116,"outputs":[]},{"cell_type":"code","metadata":{"id":"005fJqGhEPPZ","executionInfo":{"status":"ok","timestamp":1634593886889,"user_tz":240,"elapsed":6,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["class BeijingPM25Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, path: str):\n","\n","        # Read the input file.\n","        fields = ['year','month','day','hour','DEWP','TEMP','PRES','Is','Ir'] # Specific columns to use.\n","        self.df = pd.read_csv(path, usecols=fields)\n","\n","        # # Create single date column from independent year/month/day columns.\n","        # self.df = self.df.assign(date=pd.to_datetime(df[['year','month','day','hour']]))\n","\n","        # Add health scores to the dataset for specific plants.\n","        # These scores are normalized between [0,1].\n","        features = ['tomato', 'sunflower', 'cucumber']\n","        self.df = self.df.assign(**{feat:np.random.uniform(0.0, 1.0, size=self.df.shape[0]) for feat in features})\n","\n","        # Separate dataset into source (input) and target (output).\n","        # self.src = df[['date', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        self.src = self.df[['year','month','day','hour', 'DEWP', 'TEMP', 'PRES', 'Is', 'Ir']].to_numpy()\n","        self.tgt = self.df[['tomato', 'sunflower', 'cucumber']].to_numpy()\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        src = self.src[index]\n","        tgt = self.tgt[index]\n","        return src, tgt"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"dinxQl1IwZ-H","executionInfo":{"status":"ok","timestamp":1634593887047,"user_tz":240,"elapsed":164,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Load the dataset from file.\n","csvfile = os.path.join(dataset_root, \"beijing_pm2.5\", \"PRSA_data_2010.1.1-2014.12.31.csv\")\n","dataset = BeijingPM25Dataset(csvfile)"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLb4BoQcxtkY","executionInfo":{"status":"ok","timestamp":1634593887048,"user_tz":240,"elapsed":4,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Create a dataset loader to assist with batching.\n","batch_size = 32\n","loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"],"execution_count":119,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KqI9yLsvGhJu"},"source":["## Model Definition"]},{"cell_type":"code","metadata":{"id":"28u0APtCGjqj","executionInfo":{"status":"ok","timestamp":1634593887048,"user_tz":240,"elapsed":3,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["import torch.nn"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0u-z53OhXWCC"},"source":["#### Transformer for Time-Series Forecasting"]},{"cell_type":"code","metadata":{"id":"7pqfmWgrR28-","executionInfo":{"status":"ok","timestamp":1634593887049,"user_tz":240,"elapsed":4,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["def create_attn_mask(length: int, device: str = None):\n","    \"\"\"Generate mask used for attention mechanisms.\n","\n","    Masks are a lower-triangular matrix of zeros\n","    with the other entries taking value \"-inf\".\n","\n","    Args:\n","        length (int): Length of square-matrix dimension.\n","        device (str, optional): PyTorch device.\n","\n","    Examples:\n","\n","        >>> create_mask(3)\n","        tensor([[0., -inf, -inf],\n","                [0., 0., -inf],\n","                [0., 0., 0.]])\n","    \"\"\"\n","    # Get lower-triangular matrix of ones.\n","    mask = torch.tril(torch.ones(length, length, device=device))\n","\n","    # Replace 0 -> \"-inf\" and 1 -> 0.0\n","    mask = (\n","        mask\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbndVAAOGnsN","executionInfo":{"status":"ok","timestamp":1634593887199,"user_tz":240,"elapsed":154,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["class TimeSeriesTransformer(torch.nn.Module):\n","\n","    def __init__(self,\n","        n_encoder_inputs: int,\n","        n_decoder_inputs: int,\n","        d_model: int = 512,\n","        dropout: float = 0.1,\n","        batch_first: bool = False,\n","        ):\n","        super().__init__()\n","\n","        self.batch_first = batch_first\n","\n","        # Linear transformation from input-feature space into arbitrary n-dimension space.\n","        # This is similar to a word embedding used in NLP tasks.\n","        self.encoder_projection = torch.nn.Linear(in_features=n_encoder_inputs, out_features=d_model)\n","        self.decoder_projection = torch.nn.Linear(in_features=n_decoder_inputs, out_features=d_model)\n","\n","        # Transformer encoder/decoder layers.\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        decoder_layer = torch.nn.TransformerDecoderLayer(\n","            d_model=d_model,\n","            nhead=8, # Number of multihead-attention models.\n","            dropout=dropout,\n","            dim_feedforward=4*d_model,\n","            batch_first=batch_first,\n","        )\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=8)\n","        self.decoder = torch.nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=8)\n","\n","        # Linear output layer.\n","        # We only predict a single data point at a time, so output features is 1.\n","        self.linear = torch.nn.Linear(in_features=d_model, out_features=1)\n","\n","\n","    def encode(self, src):\n","        # Transform source into arbitrary feature space.\n","        x = self.encoder_projection(src)\n","\n","        # Pass the linear transformation through the encoder layers.\n","        x = self.encoder(x)\n","\n","        return x\n","\n","\n","    def decode(self, tgt, memory):\n","        # Transform target into arbitrary feature space.\n","        x = self.decoder_projection(tgt)\n","\n","        # Create target attention mask.\n","        if self.batch_first:\n","            tgt_length, batch_size = tgt.size(1), tgt.size(0)\n","        else:\n","            tgt_length, batch_size = tgt.size(0), tgt.size(1)\n","        tgt_mask = create_attn_mask(length=tgt_length, device=tgt.device)\n","\n","        # Pass the linear transformation through the decoder layers.\n","        x = self.decoder(tgt=x, memory=memory, tgt_mask=tgt_mask)\n","\n","        # Pass the output of the decoder through the linear prediction layer.\n","        x = self.linear(x)\n","\n","        return x\n","\n","\n","    def forward(self, x):\n","        src, tgt = x\n","        y = self.encode(src)\n","        y = self.decode(tgt=tgt, memory=y)\n","        return y"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZ198-xWmAyv","executionInfo":{"status":"ok","timestamp":1634593887798,"user_tz":240,"elapsed":601,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":["# Prediction problem setup.\n","#\n","# Given 24 hours of data points, predict the next 1 hour of data points.\n","n_encoder_inputs = 24 # Number of data points in input sequence.\n","n_decoder_inputs = 1 # Number of data points in output sequence.\n","\n","d_model = 512 # Latent dimension.\n","dropout = 0.1\n","\n","# Create new model.\n","model = TimeSeriesTransformer(\n","    n_encoder_inputs,\n","    n_decoder_inputs,\n","    d_model,\n","    dropout,\n",")"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fq5Kkl5bRT1E","executionInfo":{"status":"ok","timestamp":1634593888662,"user_tz":240,"elapsed":866,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}},"outputId":"614018c7-0ca6-4e9c-cc3a-ae804d135943"},"source":["# Test the forward method.\n","n_records = 10\n","src = torch.rand(size=(batch_size, n_records, n_encoder_inputs))\n","target_in = torch.rand(size=(batch_size, n_records, n_decoder_inputs))\n","\n","pred = model((src, target_in))\n","print(pred.size())"],"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 10, 1])\n"]}]},{"cell_type":"code","metadata":{"id":"Fc-4PSGjW-Bj","executionInfo":{"status":"ok","timestamp":1634593888663,"user_tz":240,"elapsed":4,"user":{"displayName":"Alexander DeRieux","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXMvSXQtaWB75iKecg6p0SbX3z5jmeUWh8Esnzkg=s64","userId":"11983099067437663618"}}},"source":[""],"execution_count":124,"outputs":[]}]}